{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOzYFdpeqNeh"
      },
      "source": [
        "# NLP Powered Research Assistant\n",
        "### Helit Bauberg, 027466002\n",
        "### Tali Aharon,   034791236\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup environment"
      ],
      "metadata": {
        "id": "5u34NTjU9tTb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8KaVwPrvppSJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "028494a4-a90b-4144-8b74-2d1e352a551f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.6/990.6 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m384.0/384.0 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.2/140.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.6/318.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq google-generativeai      #Gemini\n",
        "!pip install -Uq google-search-results    #Google Search (SERP)\n",
        "!pip install -Uq langchain\n",
        "!pip install -Uq langchain-google-genai\n",
        "!pip install -Uq langchain_community\n",
        "!pip install -Uq tiktoken\n",
        "!pip install -Uq requests #==2.31.0         #Otherwise colab complains\n",
        "!pip install -Uq Arxiv                    #Arxiv search and retrieval\n",
        "!pip install -Uq gradio                   # Chatbot Web GUI\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YwKikw-KyCu",
        "outputId": "f535c5c2-9299-42e0-a73b-b7b4a1561899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "['.ipynb_checkpoints', '__pycache__', 'ResearchAss (1).py', 'image.png', 'ResearchAss.py', 'README.md']\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'Colab Notebooks/NLP_RA'\n",
        "GOOGLE_DRIVE_PATH = os.path.join('drive', 'My Drive', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n",
        "\n",
        "sys.path.append(GOOGLE_DRIVE_PATH)\n",
        "print(os.listdir(GOOGLE_DRIVE_PATH))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dqkHUXCYPjpv"
      },
      "outputs": [],
      "source": [
        "# This allows automatic reloading of modules before executing code, ensuring the latest version of any imported module is used.\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi9uJMuaqwH4"
      },
      "source": [
        "## Testing individual functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u5HvylQMj31",
        "outputId": "658c4490-f730-4dfd-d1ea-d32483918f0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Ballad of the Human Brain**\n",
            "\n",
            "In realms of gray and circuitry's maze,\n",
            "A marvel dwells, a masterpiece we praise.\n",
            "The brain, a wondrous organ, beyond compare,\n",
            "A symphony of neurons, a thought's lair.\n",
            "\n",
            "It processes and stores, a vast domain,\n",
            "From memories of joy to moments of pain.\n",
            "It governs our actions, guides our way,\n",
            "A master of perception, come what may.\n",
            "\n",
            "Emotions, like waves upon the shore,\n",
            "Crash and flow within its depths galore.\n",
            "Reason and instinct, a delicate dance,\n",
            "As we navigate life's ever-changing trance.\n",
            "\n",
            "The senses it receives, a tapestry of sight,\n",
            "Sound, smell, and touch, illuminating the night.\n",
            "It weaves these threads into a vivid scene,\n",
            "A kaleidoscope of wonders, ever so keen.\n",
            "\n",
            "Language, a gift, at its command,\n",
            "It shapes our thoughts, allows us to expand.\n",
            "Through words it paints pictures, tells stories untold,\n",
            "Connecting minds, a treasure to behold.\n",
            "\n",
            "Yet with its power comes a fragile frame,\n",
            "Susceptible to wounds, disease, and shame.\n",
            "Trauma and stress can leave their mark,\n",
            "Altering its course, leaving an enduring spark.\n",
            "\n",
            "But even in darkness, hope still gleams,\n",
            "For neuroplasticity, a transformative stream.\n",
            "With effort and care, we can rebuild,\n",
            "Reconnect neurons, restore what was stilled.\n",
            "\n",
            "So let us marvel at this organ supreme,\n",
            "The human brain, a constant, living dream.\n",
            "May we cherish its gifts, protect its might,\n",
            "And explore its mysteries with all our light.\n"
          ]
        }
      ],
      "source": [
        "# Test direct llm call API\n",
        "\n",
        "from ResearchAss import get_llm\n",
        "\n",
        "llm = get_llm(0.8)\n",
        "result = llm.invoke(\"Write a ballad about the human brain\")\n",
        "print(result.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb87oCio0uPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8f4f151-92a9-45b4-cec3-1c40ac9a70a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Large Language Models for Knowledge Graph Construction',\n",
              " 'LLM-based Knowledge Graph Extraction',\n",
              " 'Knowledge Graph Augmentation with LLM']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# get_queries - llm optimization of search query\n",
        "\n",
        "from ResearchAss import get_queries\n",
        "\n",
        "p = get_queries(\"LLM models for knowledge graph\")\n",
        "p.splitlines()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEnYghf1PO1J"
      },
      "outputs": [],
      "source": [
        "# Perform a Google Scholar search for papers related to search query and retrieve their Arxiv IDs.\n",
        "from ResearchAss import search_gscholar\n",
        "\n",
        "ids = search_gscholar(\"LLM-based Knowledge Graph Extraction\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5WfGBX_gtYu",
        "outputId": "66fa0aa8-da07-424f-d080-447d4d060bf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2404.03868',\n",
              " '2403.03008',\n",
              " '2402.04978',\n",
              " '2403.07311',\n",
              " '2407.04363',\n",
              " '2407.13598',\n",
              " '2406.03746']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ResearchAss import remove_duplicates\n",
        "\n",
        "lis = ['2404.03868',\n",
        " '2403.03008',\n",
        " '2402.04978',\n",
        " '2403.07311',\n",
        " '2407.04363',\n",
        " '2407.13598',\n",
        " '2406.03746',\n",
        " '2407.04363',\n",
        "       ]\n",
        "l = remove_duplicates(lis)\n",
        "print(l)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jc5vqWOJ2zL7",
        "outputId": "60c91172-5e14-4361-e051-46f632bc5b46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate found! 2407.04363\n",
            "Added 7 unique records\n",
            "['2404.03868', '2403.03008', '2402.04978', '2403.07311', '2407.04363', '2407.13598', '2406.03746']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQUBBVPKhSh1",
        "outputId": "d367fe25-fc9a-408e-df31-d42ec3ae7eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Arxiv doc count: 7\n"
          ]
        }
      ],
      "source": [
        "# Search for papers on Arxiv using the retrieved list of Arxiv IDs from the Google Scholar search.\n",
        "\n",
        "from ResearchAss import search_arxiv\n",
        "\n",
        "papers = search_arxiv(ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ4ZZy5Pz5Je",
        "outputId": "526da8a9-c4cc-4551-d906-cbf132813884"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'Entry ID': 'http://arxiv.org/abs/2404.03868v1', 'Published': datetime.date(2024, 4, 5), 'Title': 'Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction', 'Authors': 'Bowen Zhang, Harold Soh'}, page_content=\"In this work, we are interested in automated methods for knowledge graph\\ncreation (KGC) from input text. Progress on large language models (LLMs) has\\nprompted a series of recent works applying them to KGC, e.g., via zero/few-shot\\nprompting. Despite successes on small domain-specific datasets, these models\\nface difficulties scaling up to text common in many real-world applications. A\\nprincipal issue is that in prior methods, the KG schema has to be included in\\nthe LLM prompt to generate valid triplets; larger and more complex schema\\neasily exceed the LLMs' context window length. To address this problem, we\\npropose a three-phase framework named Extract-Define-Canonicalize (EDC): open\\ninformation extraction followed by schema definition and post-hoc\\ncanonicalization. EDC is flexible in that it can be applied to settings where a\\npre-defined target schema is available and when it is not; in the latter case,\\nit constructs a schema automatically and applies self-canonicalization. To\\nfurther improve performance, we introduce a trained component that retrieves\\nschema elements relevant to the input text; this improves the LLMs' extraction\\nperformance in a retrieval-augmented generation-like manner. We demonstrate on\\nthree KGC benchmarks that EDC is able to extract high-quality triplets without\\nany parameter tuning and with significantly larger schemas compared to prior\\nworks.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2403.03008v1', 'Published': datetime.date(2024, 3, 5), 'Title': 'Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations', 'Authors': 'Hasan Abu-Rasheed, Christian Weber, Madjid Fathi'}, page_content=\"In the era of personalized education, the provision of comprehensible\\nexplanations for learning recommendations is of a great value to enhance the\\nlearner's understanding and engagement with the recommended learning content.\\nLarge language models (LLMs) and generative AI in general have recently opened\\nnew doors for generating human-like explanations, for and along learning\\nrecommendations. However, their precision is still far away from acceptable in\\na sensitive field like education. To harness the abilities of LLMs, while still\\nensuring a high level of precision towards the intent of the learners, this\\npaper proposes an approach to utilize knowledge graphs (KG) as a source of\\nfactual context, for LLM prompts, reducing the risk of model hallucinations,\\nand safeguarding against wrong or imprecise information, while maintaining an\\napplication-intended learning context. We utilize the semantic relations in the\\nknowledge graph to offer curated knowledge about learning recommendations. With\\ndomain-experts in the loop, we design the explanation as a textual template,\\nwhich is filled and completed by the LLM. Domain experts were integrated in the\\nprompt engineering phase as part of a study, to ensure that explanations\\ninclude information that is relevant to the learner. We evaluate our approach\\nquantitatively using Rouge-N and Rouge-L measures, as well as qualitatively\\nwith experts and learners. Our results show an enhanced recall and precision of\\nthe generated explanations compared to those generated solely by the GPT model,\\nwith a greatly reduced risk of generating imprecise information in the final\\nlearning explanation.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2402.04978v2', 'Published': datetime.date(2024, 6, 12), 'Title': 'An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration', 'Authors': 'Yihao Li, Ru Zhang, Jianyi Liu'}, page_content=\"While Large Language Models (LLMs) demonstrate exceptional performance in a\\nmultitude of Natural Language Processing (NLP) tasks, they encounter challenges\\nin practical applications, including issues with hallucinations, inadequate\\nknowledge updating, and limited transparency in the reasoning process. To\\novercome these limitations, this study innovatively proposes a collaborative\\ntraining-free reasoning scheme involving tight cooperation between Knowledge\\nGraph (KG) and LLMs. This scheme first involves using LLMs to iteratively\\nexplore KG, selectively retrieving a task-relevant knowledge subgraph to\\nsupport reasoning. The LLMs are then guided to further combine inherent\\nimplicit knowledge to reason on the subgraph while explicitly elucidating the\\nreasoning process. Through such a cooperative approach, our scheme achieves\\nmore reliable knowledge-based reasoning and facilitates the tracing of the\\nreasoning results. Experimental results show that our scheme significantly\\nprogressed across multiple datasets, notably achieving over a 10% improvement\\non the QALD10 dataset compared to the best baseline and the fine-tuned\\nstate-of-the-art (SOTA) work. Building on this success, this study hopes to\\noffer a valuable reference for future research in the fusion of KG and LLMs,\\nthereby enhancing LLMs' proficiency in solving complex issues.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2403.07311v7', 'Published': datetime.date(2024, 7, 2), 'Title': 'Knowledge Graph Large Language Model (KG-LLM) for Link Prediction', 'Authors': 'Dong Shu, Tianle Chen, Mingyu Jin, Chong Zhang, Mengnan Du, Yongfeng Zhang'}, page_content=\"The task of multi-hop link prediction within knowledge graphs (KGs) stands as\\na challenge in the field of knowledge graph analysis, as it requires the model\\nto reason through and understand all intermediate connections before making a\\nprediction. In this paper, we introduce the Knowledge Graph Large Language\\nModel (KG-LLM), a novel framework that leverages large language models (LLMs)\\nfor knowledge graph tasks. We first convert structured knowledge graph data\\ninto natural language and then use these natural language prompts to fine-tune\\nLLMs to enhance multi-hop link prediction in KGs. By converting the KG to\\nnatural language prompts, our framework is designed to learn the latent\\nrepresentations of entities and their interrelations. To show the efficacy of\\nthe KG-LLM Framework, we fine-tune three leading LLMs within this framework,\\nincluding Flan-T5, LLaMa2 and Gemma. Further, we explore the framework's\\npotential to provide LLMs with zero-shot capabilities for handling previously\\nunseen prompts. Experimental results show that KG-LLM significantly improves\\nthe models' generalization capabilities, leading to more accurate predictions\\nin unfamiliar scenarios.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2407.04363v1', 'Published': datetime.date(2024, 7, 5), 'Title': 'AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents', 'Authors': 'Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev'}, page_content=\"Advancements in generative AI have broadened the potential applications of\\nLarge Language Models (LLMs) in the development of autonomous agents. Achieving\\ntrue autonomy requires accumulating and updating knowledge gained from\\ninteractions with the environment and effectively utilizing it. Current\\nLLM-based approaches leverage past experiences using a full history of\\nobservations, summarization or retrieval augmentation. However, these\\nunstructured memory representations do not facilitate the reasoning and\\nplanning essential for complex decision-making. In our study, we introduce\\nAriGraph, a novel method wherein the agent constructs a memory graph that\\nintegrates semantic and episodic memories while exploring the environment. This\\ngraph structure facilitates efficient associative retrieval of interconnected\\nconcepts, relevant to the agent's current state and goals, thus serving as an\\neffective environmental model that enhances the agent's exploratory and\\nplanning capabilities. We demonstrate that our Ariadne LLM agent, equipped with\\nthis proposed memory architecture augmented with planning and decision-making,\\neffectively handles complex tasks on a zero-shot basis in the TextWorld\\nenvironment. Our approach markedly outperforms established methods such as\\nfull-history, summarization, and Retrieval-Augmented Generation in various\\ntasks, including the cooking challenge from the First TextWorld Problems\\ncompetition and novel tasks like house cleaning and puzzle Treasure Hunting.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2407.13598v1', 'Published': datetime.date(2024, 7, 18), 'Title': 'KNOWNET: Guided Health Information Seeking from LLMs via Knowledge Graph Integration', 'Authors': 'Youfu Yan, Yu Hou, Yongkang Xiao, Rui Zhang, Qianwen Wang'}, page_content='The increasing reliance on Large Language Models (LLMs) for health\\ninformation seeking can pose severe risks due to the potential for\\nmisinformation and the complexity of these topics. This paper introduces\\nKNOWNET a visualization system that integrates LLMs with Knowledge Graphs (KG)\\nto provide enhanced accuracy and structured exploration. Specifically, for\\nenhanced accuracy, KNOWNET extracts triples (e.g., entities and their\\nrelations) from LLM outputs and maps them into the validated information and\\nsupported evidence in external KGs. For structured exploration, KNOWNET\\nprovides next-step recommendations based on the neighborhood of the currently\\nexplored entities in KGs, aiming to guide a comprehensive understanding without\\noverlooking critical aspects. To enable reasoning with both the structured data\\nin KGs and the unstructured outputs from LLMs, KNOWNET conceptualizes the\\nunderstanding of a subject as the gradual construction of graph visualization.\\nA progressive graph visualization is introduced to monitor past inquiries, and\\nbridge the current query with the exploration history and next-step\\nrecommendations. We demonstrate the effectiveness of our system via use cases\\nand expert interviews.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2406.03746v1', 'Published': datetime.date(2024, 6, 6), 'Title': 'Efficient Knowledge Infusion via KG-LLM Alignment', 'Authors': 'Zhouyu Jiang, Ling Zhong, Mengshu Sun, Jun Xu, Rui Sun, Hui Cai, Shuhan Luo, Zhiqiang Zhang'}, page_content=\"To tackle the problem of domain-specific knowledge scarcity within large\\nlanguage models (LLMs), knowledge graph-retrievalaugmented method has been\\nproven to be an effective and efficient technique for knowledge infusion.\\nHowever, existing approaches face two primary challenges: knowledge mismatch\\nbetween public available knowledge graphs and the specific domain of the task\\nat hand, and poor information compliance of LLMs with knowledge graphs. In this\\npaper, we leverage a small set of labeled samples and a large-scale corpus to\\nefficiently construct domain-specific knowledge graphs by an LLM, addressing\\nthe issue of knowledge mismatch. Additionally, we propose a three-stage KG-LLM\\nalignment strategyto enhance the LLM's capability to utilize information from\\nknowledge graphs. We conduct experiments with a limited-sample setting on two\\nbiomedical question-answering datasets, and the results demonstrate that our\\napproach outperforms existing baselines.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfZu_Tpbm2R6",
        "outputId": "6fb9aa39-bfac-443c-8834-f0bd934b5f49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Arxiv doc count: 5\n"
          ]
        }
      ],
      "source": [
        "# Search for papers on Arxiv using search query\n",
        "papers = search_arxiv(\"LLM knowledge graph construction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtcibR4xiw6f",
        "outputId": "8bc41ecb-5ab3-4fac-b8de-21dbe62f1b57"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'Entry ID': 'http://arxiv.org/abs/2309.08594v1', 'Published': datetime.date(2023, 9, 15), 'Title': '\"Merge Conflicts!\" Exploring the Impacts of External Distractors to Parametric Knowledge Graphs', 'Authors': 'Cheng Qian, Xinran Zhao, Sherry Tongshuang Wu'}, page_content='Large language models (LLMs) acquire extensive knowledge during pre-training,\\nknown as their parametric knowledge. However, in order to remain up-to-date and\\nalign with human instructions, LLMs inevitably require external knowledge\\nduring their interactions with users. This raises a crucial question: How will\\nLLMs respond when external knowledge interferes with their parametric\\nknowledge? To investigate this question, we propose a framework that\\nsystematically elicits LLM parametric knowledge and introduces external\\nknowledge. Specifically, we uncover the impacts by constructing a parametric\\nknowledge graph to reveal the different knowledge structures of LLMs, and\\nintroduce external knowledge through distractors of varying degrees, methods,\\npositions, and formats. Our experiments on both black-box and open-source\\nmodels demonstrate that LLMs tend to produce responses that deviate from their\\nparametric knowledge, particularly when they encounter direct conflicts or\\nconfounding changes of information within detailed contexts. We also find that\\nwhile LLMs are sensitive to the veracity of external knowledge, they can still\\nbe distracted by unrelated information. These findings highlight the risk of\\nhallucination when integrating external knowledge, even indirectly, during\\ninteractions with current LLMs. All the data and results are publicly\\navailable.')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "\n",
        "papers[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8rQM2V13OlE",
        "outputId": "2259ef49-b7ec-4ea3-f48f-5fb2b19deac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Arxiv doc count: 5\n",
            "Large Language Models for Knowledge Graph Construction ['2402.02389', '2407.10794', '2111.08546', '2310.06671', '2401.04507', '2407.16127', '2305.04676'] 5\n",
            "Total Arxiv doc count: 5\n",
            "LLM-based Knowledge Graph Extraction ['2402.02389', '2407.10794', '2111.08546', '2310.06671', '2401.04507', '2407.16127', '2305.04676', '2404.03868', '2403.03008', '2402.04978', '2403.07311', '2407.04363', '2407.13598', '2406.03746'] 10\n",
            "Total Arxiv doc count: 5\n",
            "Knowledge Graph Augmentation with LLM ['2402.02389', '2407.10794', '2111.08546', '2310.06671', '2401.04507', '2407.16127', '2305.04676', '2404.03868', '2403.03008', '2402.04978', '2403.07311', '2407.04363', '2407.13598', '2406.03746', '2406.17231', '2407.04363', '2405.15436', '2402.04978', '2404.03868', '2403.08345', '2403.07311', '2406.03746', '2404.14741'] 15\n",
            "Total Arxiv doc count: 5\n"
          ]
        }
      ],
      "source": [
        "# get_papers - this method retrieves matching papers from both Arxiv and Google Scholar based on the generated search queries.\n",
        "from ResearchAss import get_papers\n",
        "\n",
        "papers = get_papers(p)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "papers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxdP9FGWLZZs",
        "outputId": "c0c24f0a-8363-410e-9ac5-0865b52083bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'Entry ID': 'http://arxiv.org/abs/2308.10173v1', 'Published': datetime.date(2023, 8, 20), 'Title': 'FoodGPT: A Large Language Model in Food Testing Domain with Incremental Pre-training and Knowledge Graph Prompt', 'Authors': 'Zhixiao Qi, Yijiong Yu, Meiqi Tu, Junyi Tan, Yongfeng Huang'}, page_content='Currently, the construction of large language models in specific domains is\\ndone by fine-tuning on a base model. Some models also incorporate knowledge\\nbases without the need for pre-training. This is because the base model already\\ncontains domain-specific knowledge during the pre-training process. We build a\\nlarge language model for food testing. Unlike the above approach, a significant\\namount of data in this domain exists in Scanning format for domain standard\\ndocuments. In addition, there is a large amount of untrained structured\\nknowledge. Therefore, we introduce an incremental pre-training step to inject\\nthis knowledge into a large language model. In this paper, we propose a method\\nfor handling structured knowledge and scanned documents in incremental\\npre-training. To overcome the problem of machine hallucination, we constructe a\\nknowledge graph to serve as an external knowledge base for supporting retrieval\\nin the large language model. It is worth mentioning that this paper is a\\ntechnical report of our pre-release version, and we will report our specific\\nexperimental data in future versions.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2303.04794v1', 'Published': datetime.date(2023, 3, 8), 'Title': 'Comprehensive Event Representations using Event Knowledge Graphs and Natural Language Processing', 'Authors': 'Tin Kuculo'}, page_content='Recent work has utilised knowledge-aware approaches to natural language\\nunderstanding, question answering, recommendation systems, and other tasks.\\nThese approaches rely on well-constructed and large-scale knowledge graphs that\\ncan be useful for many downstream applications and empower knowledge-aware\\nmodels with commonsense reasoning. Such knowledge graphs are constructed\\nthrough knowledge acquisition tasks such as relation extraction and knowledge\\ngraph completion. This work seeks to utilise and build on the growing body of\\nwork that uses findings from the field of natural language processing (NLP) to\\nextract knowledge from text and build knowledge graphs. The focus of this\\nresearch project is on how we can use transformer-based approaches to extract\\nand contextualise event information, matching it to existing ontologies, to\\nbuild a comprehensive knowledge of graph-based event representations.\\nSpecifically, sub-event extraction is used as a way of creating sub-event-aware\\nevent representations. These event representations are then further enriched\\nthrough fine-grained location extraction and contextualised through the\\nalignment of historically relevant quotes.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2308.13782v2', 'Published': datetime.date(2024, 7, 5), 'Title': 'Planning with Logical Graph-based Language Model for Instruction Generation', 'Authors': 'Fan Zhang, Kebing Jin, Hankz Hankui Zhuo'}, page_content='Despite the superior performance of large language models to generate natural\\nlanguage texts, it is hard to generate texts with correct logic according to a\\ngiven task, due to the difficulties for neural models to capture implied rules\\nfrom free-form texts. In this paper, we propose a novel graph-based language\\nmodel, Logical-GLM, to infuse logic into language models for more valid text\\ngeneration and interpretability. Specifically, we first capture information\\nfrom natural language instructions and construct logical bayes graphs that\\ngenerally describe domains. Next, we generate logical skeletons to guide\\nlanguage model training, infusing domain knowledge into language models.\\nFinally, we alternately optimize the searching policy of graphs and language\\nmodels until convergence. The experimental results show that Logical-GLM is\\nboth effective and efficient compared with traditional language models, despite\\nusing smaller-scale training data and fewer parameters. Our approach can\\ngenerate instructional texts with more correct logic owing to the internalized\\ndomain knowledge. Moreover, the usage of logical graphs reflects the inner\\nmechanism of the language models, which improves the interpretability of\\nblack-box models.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2407.00653v1', 'Published': datetime.date(2024, 6, 30), 'Title': 'Chain-of-Knowledge: Integrating Knowledge Reasoning into Large Language Models by Learning from Knowledge Graphs', 'Authors': 'Yifei Zhang, Xintao Wang, Jiaqing Liang, Sirui Xia, Lida Chen, Yanghua Xiao'}, page_content='Large Language Models (LLMs) have exhibited impressive proficiency in various\\nnatural language processing (NLP) tasks, which involve increasingly complex\\nreasoning. Knowledge reasoning, a primary type of reasoning, aims at deriving\\nnew knowledge from existing one.While it has been widely studied in the context\\nof knowledge graphs (KGs), knowledge reasoning in LLMs remains underexplored.\\nIn this paper, we introduce Chain-of-Knowledge, a comprehensive framework for\\nknowledge reasoning, including methodologies for both dataset construction and\\nmodel learning. For dataset construction, we create KnowReason via rule mining\\non KGs. For model learning, we observe rule overfitting induced by naive\\ntraining. Hence, we enhance CoK with a trial-and-error mechanism that simulates\\nthe human process of internal knowledge exploration. We conduct extensive\\nexperiments with KnowReason. Our results show the effectiveness of CoK in\\nrefining LLMs in not only knowledge reasoning, but also general reasoning\\nbenchmarkms.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2210.15248v2', 'Published': datetime.date(2022, 10, 28), 'Title': 'Unsupervised Knowledge Graph Construction and Event-centric Knowledge Infusion for Scientific NLI', 'Authors': 'Chenglin Wang, Yucheng Zhou, Guodong Long, Xiaodong Wang, Xiaowei Xu'}, page_content='With the advance of natural language inference (NLI), a rising demand for NLI\\nis to handle scientific texts. Existing methods depend on pre-trained models\\n(PTM) which lack domain-specific knowledge. To tackle this drawback, we\\nintroduce a scientific knowledge graph to generalize PTM to scientific domain.\\nHowever, existing knowledge graph construction approaches suffer from some\\ndrawbacks, i.e., expensive labeled data, failure to apply in other domains,\\nlong inference time and difficulty extending to large corpora. Therefore, we\\npropose an unsupervised knowledge graph construction method to build a\\nscientific knowledge graph (SKG) without any labeled data. Moreover, to\\nalleviate noise effect from SKG and complement knowledge in sentences better,\\nwe propose an event-centric knowledge infusion method to integrate external\\nknowledge into each event that is a fine-grained semantic unit in sentences.\\nExperimental results show that our method achieves state-of-the-art performance\\nand the effectiveness and reliability of SKG.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2210.11231v3', 'Published': datetime.date(2023, 4, 25), 'Title': 'Knowledge-Enhanced Relation Extraction Dataset', 'Authors': 'Yucong Lin, Hongming Xiao, Jiani Liu, Zichao Lin, Keming Lu, Feifei Wang, Wei Wei'}, page_content='Recently, knowledge-enhanced methods leveraging auxiliary knowledge graphs\\nhave emerged in relation extraction, surpassing traditional text-based\\napproaches. However, to our best knowledge, there is currently no public\\ndataset available that encompasses both evidence sentences and knowledge graphs\\nfor knowledge-enhanced relation extraction. To address this gap, we introduce\\nthe Knowledge-Enhanced Relation Extraction Dataset (KERED). KERED annotates\\neach sentence with a relational fact, and it provides knowledge context for\\nentities through entity linking. Using our curated dataset, We compared\\ncontemporary relation extraction methods under two prevalent task settings:\\nsentence-level and bag-level. The experimental result shows the knowledge\\ngraphs provided by KERED can support knowledge-enhanced relation extraction\\nmethods. We believe that KERED offers high-quality relation extraction datasets\\nwith corresponding knowledge graphs for evaluating the performance of\\nknowledge-enhanced relation extraction methods. Our dataset is available at:\\n\\\\url{https://figshare.com/projects/KERED/134459}'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2405.02463v1', 'Published': datetime.date(2024, 5, 3), 'Title': 'Knowledge Graph Extension by Entity Type Recognition', 'Authors': 'Daqian Shi'}, page_content='Knowledge graphs have emerged as a sophisticated advancement and refinement\\nof semantic networks, and their deployment is one of the critical methodologies\\nin contemporary artificial intelligence. The construction of knowledge graphs\\nis a multifaceted process involving various techniques, where researchers aim\\nto extract the knowledge from existing resources for the construction since\\nbuilding from scratch entails significant labor and time costs. However, due to\\nthe pervasive issue of heterogeneity, the description diversity across\\ndifferent knowledge graphs can lead to mismatches between concepts, thereby\\nimpacting the efficacy of knowledge extraction. This Ph.D. study focuses on\\nautomatic knowledge graph extension, i.e., properly extending the reference\\nknowledge graph by extracting and integrating concepts from one or more\\ncandidate knowledge graphs. We propose a novel knowledge graph extension\\nframework based on entity type recognition. The framework aims to achieve\\nhigh-quality knowledge extraction by aligning the schemas and entities across\\ndifferent knowledge graphs, thereby enhancing the performance of the extension.\\nThis paper elucidates three major contributions: (i) we propose an entity type\\nrecognition method exploiting machine learning and property-based similarities\\nto enhance knowledge extraction; (ii) we introduce a set of assessment metrics\\nto validate the quality of the extended knowledge graphs; (iii) we develop a\\nplatform for knowledge graph acquisition, management, and extension to benefit\\nknowledge engineers practically. Our evaluation comprehensively demonstrated\\nthe feasibility and effectiveness of the proposed extension framework and its\\nfunctionalities through quantitative experiments and case studies.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/1510.00244v1', 'Published': datetime.date(2015, 10, 1), 'Title': 'RDF Knowledge Graph Visualization From a Knowledge Extraction System', 'Authors': 'Fadhela Kerdjoudj, Olivier Curé'}, page_content='In this paper, we present a system to visualize RDF knowledge graphs. These\\ngraphs are obtained from a knowledge extraction system designed by\\nGEOLSemantics. This extraction is performed using natural language processing\\nand trigger detection. The user can visualize subgraphs by selecting some\\nontology features like concepts or individuals. The system is also\\nmultilingual, with the use of the annotated ontology in English, French, Arabic\\nand Chinese.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2303.04794v1', 'Published': datetime.date(2023, 3, 8), 'Title': 'Comprehensive Event Representations using Event Knowledge Graphs and Natural Language Processing', 'Authors': 'Tin Kuculo'}, page_content='Recent work has utilised knowledge-aware approaches to natural language\\nunderstanding, question answering, recommendation systems, and other tasks.\\nThese approaches rely on well-constructed and large-scale knowledge graphs that\\ncan be useful for many downstream applications and empower knowledge-aware\\nmodels with commonsense reasoning. Such knowledge graphs are constructed\\nthrough knowledge acquisition tasks such as relation extraction and knowledge\\ngraph completion. This work seeks to utilise and build on the growing body of\\nwork that uses findings from the field of natural language processing (NLP) to\\nextract knowledge from text and build knowledge graphs. The focus of this\\nresearch project is on how we can use transformer-based approaches to extract\\nand contextualise event information, matching it to existing ontologies, to\\nbuild a comprehensive knowledge of graph-based event representations.\\nSpecifically, sub-event extraction is used as a way of creating sub-event-aware\\nevent representations. These event representations are then further enriched\\nthrough fine-grained location extraction and contextualised through the\\nalignment of historically relevant quotes.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2302.05019v1', 'Published': datetime.date(2023, 2, 10), 'Title': 'A Comprehensive Survey on Automatic Knowledge Graph Construction', 'Authors': 'Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, Xindong Wu'}, page_content='Automatic knowledge graph construction aims to manufacture structured human\\nknowledge. To this end, much effort has historically been spent extracting\\ninformative fact patterns from different data sources. However, more recently,\\nresearch interest has shifted to acquiring conceptualized structured knowledge\\nbeyond informative data. In addition, researchers have also been exploring new\\nways of handling sophisticated construction tasks in diversified scenarios.\\nThus, there is a demand for a systematic review of paradigms to organize\\nknowledge structures beyond data-level mentions. To meet this demand, we\\ncomprehensively survey more than 300 methods to summarize the latest\\ndevelopments in knowledge graph construction. A knowledge graph is built in\\nthree steps: knowledge acquisition, knowledge refinement, and knowledge\\nevolution. The processes of knowledge acquisition are reviewed in detail,\\nincluding obtaining entities with fine-grained types and their conceptual\\nlinkages to knowledge graphs; resolving coreferences; and extracting entity\\nrelationships in complex scenarios. The survey covers models for knowledge\\nrefinement, including knowledge graph completion, and knowledge fusion. Methods\\nto handle knowledge evolution are also systematically presented, including\\ncondition knowledge acquisition, condition knowledge graph completion, and\\nknowledge dynamic. We present the paradigms to compare the distinction among\\nthese methods along the axis of the data environment, motivation, and\\narchitecture. Additionally, we also provide briefs on accessible resources that\\ncan help readers to develop practical knowledge graph systems. The survey\\nconcludes with discussions on the challenges and possible directions for future\\nexploration.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2404.14809v1', 'Published': datetime.date(2024, 4, 23), 'Title': 'A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications', 'Authors': 'Wenbo Shang, Xin Huang'}, page_content=\"A graph is a fundamental data model to represent various entities and their\\ncomplex relationships in society and nature, such as social networks,\\ntransportation networks, financial networks, and biomedical systems. Recently,\\nlarge language models (LLMs) have showcased a strong generalization ability to\\nhandle various NLP and multi-mode tasks to answer users' arbitrary questions\\nand specific-domain content generation. Compared with graph learning models,\\nLLMs enjoy superior advantages in addressing the challenges of generalizing\\ngraph tasks by eliminating the need for training graph learning models and\\nreducing the cost of manual annotation. In this survey, we conduct a\\ncomprehensive investigation of existing LLM studies on graph data, which\\nsummarizes the relevant graph analytics tasks solved by advanced LLM models and\\npoints out the existing remaining challenges and future directions.\\nSpecifically, we study the key problems of LLM-based generative graph analytics\\n(LLM-GGA) with three categories: LLM-based graph query processing (LLM-GQP),\\nLLM-based graph inference and learning (LLM-GIL), and graph-LLM-based\\napplications. LLM-GQP focuses on an integration of graph analytics techniques\\nand LLM prompts, including graph understanding and knowledge graph (KG) based\\naugmented retrieval, while LLM-GIL focuses on learning and reasoning over\\ngraphs, including graph learning, graph-formed reasoning and graph\\nrepresentation. We summarize the useful prompts incorporated into LLM to handle\\ndifferent graph downstream tasks. Moreover, we give a summary of LLM model\\nevaluation, benchmark datasets/tasks, and a deep pro and cons analysis of LLM\\nmodels. We also explore open problems and future directions in this exciting\\ninterdisciplinary research area of LLMs and graph analytics.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2404.07103v2', 'Published': datetime.date(2024, 7, 15), 'Title': 'Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs', 'Authors': 'Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Zheng Li, Ruirui Li, Xianfeng Tang, Suhang Wang, Yu Meng, Jiawei Han'}, page_content='Large language models (LLMs), while exhibiting exceptional performance,\\nsuffer from hallucinations, especially on knowledge-intensive tasks. Existing\\nworks propose to augment LLMs with individual text units retrieved from\\nexternal knowledge corpora to alleviate the issue. However, in many domains,\\ntexts are interconnected (e.g., academic papers in a bibliographic graph are\\nlinked by citations and co-authorships) which form a (text-attributed) graph.\\nThe knowledge in such graphs is encoded not only in single texts/nodes but also\\nin their associated connections. To facilitate the research of augmenting LLMs\\nwith graphs, we manually construct a Graph Reasoning Benchmark dataset called\\nGRBench, containing 1,740 questions that can be answered with the knowledge\\nfrom 10 domain graphs. Then, we propose a simple and effective framework called\\nGraph Chain-of-thought (Graph-CoT) to augment LLMs with graphs by encouraging\\nLLMs to reason on the graph iteratively. Each Graph-CoT iteration consists of\\nthree sub-steps: LLM reasoning, LLM-graph interaction, and graph execution. We\\nconduct systematic experiments with three LLM backbones on GRBench, where\\nGraph-CoT outperforms the baselines consistently. The code is available at\\nhttps://github.com/PeterGriffinJin/Graph-CoT.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2402.13593v1', 'Published': datetime.date(2024, 2, 21), 'Title': 'Knowledge Graph Enhanced Large Language Model Editing', 'Authors': 'Mengqi Zhang, Xiaotian Ye, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen'}, page_content='Large language models (LLMs) are pivotal in advancing natural language\\nprocessing (NLP) tasks, yet their efficacy is hampered by inaccuracies and\\noutdated knowledge. Model editing emerges as a promising solution to address\\nthese challenges. However, existing editing methods struggle to track and\\nincorporate changes in knowledge associated with edits, which limits the\\ngeneralization ability of postedit LLMs in processing edited knowledge. To\\ntackle these problems, we propose a novel model editing method that leverages\\nknowledge graphs for enhancing LLM editing, namely GLAME. Specifically, we\\nfirst utilize a knowledge graph augmentation module to uncover associated\\nknowledge that has changed due to editing, obtaining its internal\\nrepresentations within LLMs. This approach allows knowledge alterations within\\nLLMs to be reflected through an external graph structure. Subsequently, we\\ndesign a graph-based knowledge edit module to integrate structured knowledge\\ninto the model editing. This ensures that the updated parameters reflect not\\nonly the modifications of the edited knowledge but also the changes in other\\nassociated knowledge resulting from the editing process. Comprehensive\\nexperiments conducted on GPT-J and GPT-2 XL demonstrate that GLAME\\nsignificantly improves the generalization capabilities of post-edit LLMs in\\nemploying edited knowledge.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2406.17231v1', 'Published': datetime.date(2024, 6, 25), 'Title': 'CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph', 'Authors': 'Tong Zhou, Yubo Chen, Kang Liu, Jun Zhao'}, page_content='Large language models have become integral to question-answering applications\\ndespite their propensity for generating hallucinations and factually inaccurate\\ncontent. Querying knowledge graphs to reduce hallucinations in LLM meets the\\nchallenge of incomplete knowledge coverage in knowledge graphs. On the other\\nhand, updating knowledge graphs by information extraction and knowledge graph\\ncompletion faces the knowledge update misalignment issue. In this work, we\\nintroduce a collaborative augmentation framework, CogMG, leveraging knowledge\\ngraphs to address the limitations of LLMs in QA scenarios, explicitly targeting\\nthe problems of incomplete knowledge coverage and knowledge update\\nmisalignment. The LLMs identify and decompose required knowledge triples that\\nare not present in the KG, enriching them and aligning updates with real-world\\ndemands. We demonstrate the efficacy of this approach through a supervised\\nfine-tuned LLM within an agent framework, showing significant improvements in\\nreducing hallucinations and enhancing factual accuracy in QA responses. Our\\ncode and video are publicly available.'),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2403.15736v1', 'Published': datetime.date(2024, 3, 23), 'Title': 'LLMs Instruct LLMs:An Extraction and Editing Method', 'Authors': 'Xin Zhang, Tianjie Ju, Huijia Liang, Ying Fu, Qin Zhang'}, page_content=\"The interest in updating Large Language Models (LLMs) without retraining from\\nscratch is substantial, yet it comes with some challenges.This is especially\\ntrue for situations demanding complex reasoning with limited samples, a\\nscenario we refer to as the Paucity-Constrained Complex Reasoning Adaptation\\nfor LLMs (PCRA-LLM).Traditional methods like Low-Rank Adaptation (LoRA) and\\nRetrieval-Augmented Generation (RAG) are inadequate for this critical issue,\\nparticularly evident in our exploration of a specific medical context that\\nepitomize the PCRA-LLM's distinct needs.To address the issue, we propose a\\nSequential Fusion method to incorporate knowledge from complex context into\\nLLMs. This method employs a two-stage framework: initially, it leverages\\ngeneral LLMs to construct knowledge graphs (KGs) for extracting knowledge from\\ncomplex texts; subsequently, it updates the domain LLMs through knowledge edit.\\nAccording to our method, the domain LLM achieved a 71.69\\\\% accuracy in question\\nanswering tasks. Subsequently, we broadened our assessment to a novel dataset\\nwe developed in the economics and management field, where our method realized a\\n75\\\\% accuracy. These outcomes underline the efficacy and adaptability of our\\napproach for PCRA-LLM across various domains.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2402.04978v2', 'Published': datetime.date(2024, 6, 12), 'Title': 'An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration', 'Authors': 'Yihao Li, Ru Zhang, Jianyi Liu'}, page_content=\"While Large Language Models (LLMs) demonstrate exceptional performance in a\\nmultitude of Natural Language Processing (NLP) tasks, they encounter challenges\\nin practical applications, including issues with hallucinations, inadequate\\nknowledge updating, and limited transparency in the reasoning process. To\\novercome these limitations, this study innovatively proposes a collaborative\\ntraining-free reasoning scheme involving tight cooperation between Knowledge\\nGraph (KG) and LLMs. This scheme first involves using LLMs to iteratively\\nexplore KG, selectively retrieving a task-relevant knowledge subgraph to\\nsupport reasoning. The LLMs are then guided to further combine inherent\\nimplicit knowledge to reason on the subgraph while explicitly elucidating the\\nreasoning process. Through such a cooperative approach, our scheme achieves\\nmore reliable knowledge-based reasoning and facilitates the tracing of the\\nreasoning results. Experimental results show that our scheme significantly\\nprogressed across multiple datasets, notably achieving over a 10% improvement\\non the QALD10 dataset compared to the best baseline and the fine-tuned\\nstate-of-the-art (SOTA) work. Building on this success, this study hopes to\\noffer a valuable reference for future research in the fusion of KG and LLMs,\\nthereby enhancing LLMs' proficiency in solving complex issues.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2406.03746v1', 'Published': datetime.date(2024, 6, 6), 'Title': 'Efficient Knowledge Infusion via KG-LLM Alignment', 'Authors': 'Zhouyu Jiang, Ling Zhong, Mengshu Sun, Jun Xu, Rui Sun, Hui Cai, Shuhan Luo, Zhiqiang Zhang'}, page_content=\"To tackle the problem of domain-specific knowledge scarcity within large\\nlanguage models (LLMs), knowledge graph-retrievalaugmented method has been\\nproven to be an effective and efficient technique for knowledge infusion.\\nHowever, existing approaches face two primary challenges: knowledge mismatch\\nbetween public available knowledge graphs and the specific domain of the task\\nat hand, and poor information compliance of LLMs with knowledge graphs. In this\\npaper, we leverage a small set of labeled samples and a large-scale corpus to\\nefficiently construct domain-specific knowledge graphs by an LLM, addressing\\nthe issue of knowledge mismatch. Additionally, we propose a three-stage KG-LLM\\nalignment strategyto enhance the LLM's capability to utilize information from\\nknowledge graphs. We conduct experiments with a limited-sample setting on two\\nbiomedical question-answering datasets, and the results demonstrate that our\\napproach outperforms existing baselines.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2403.07311v7', 'Published': datetime.date(2024, 7, 2), 'Title': 'Knowledge Graph Large Language Model (KG-LLM) for Link Prediction', 'Authors': 'Dong Shu, Tianle Chen, Mingyu Jin, Chong Zhang, Mengnan Du, Yongfeng Zhang'}, page_content=\"The task of multi-hop link prediction within knowledge graphs (KGs) stands as\\na challenge in the field of knowledge graph analysis, as it requires the model\\nto reason through and understand all intermediate connections before making a\\nprediction. In this paper, we introduce the Knowledge Graph Large Language\\nModel (KG-LLM), a novel framework that leverages large language models (LLMs)\\nfor knowledge graph tasks. We first convert structured knowledge graph data\\ninto natural language and then use these natural language prompts to fine-tune\\nLLMs to enhance multi-hop link prediction in KGs. By converting the KG to\\nnatural language prompts, our framework is designed to learn the latent\\nrepresentations of entities and their interrelations. To show the efficacy of\\nthe KG-LLM Framework, we fine-tune three leading LLMs within this framework,\\nincluding Flan-T5, LLaMa2 and Gemma. Further, we explore the framework's\\npotential to provide LLMs with zero-shot capabilities for handling previously\\nunseen prompts. Experimental results show that KG-LLM significantly improves\\nthe models' generalization capabilities, leading to more accurate predictions\\nin unfamiliar scenarios.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2404.03868v1', 'Published': datetime.date(2024, 4, 5), 'Title': 'Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction', 'Authors': 'Bowen Zhang, Harold Soh'}, page_content=\"In this work, we are interested in automated methods for knowledge graph\\ncreation (KGC) from input text. Progress on large language models (LLMs) has\\nprompted a series of recent works applying them to KGC, e.g., via zero/few-shot\\nprompting. Despite successes on small domain-specific datasets, these models\\nface difficulties scaling up to text common in many real-world applications. A\\nprincipal issue is that in prior methods, the KG schema has to be included in\\nthe LLM prompt to generate valid triplets; larger and more complex schema\\neasily exceed the LLMs' context window length. To address this problem, we\\npropose a three-phase framework named Extract-Define-Canonicalize (EDC): open\\ninformation extraction followed by schema definition and post-hoc\\ncanonicalization. EDC is flexible in that it can be applied to settings where a\\npre-defined target schema is available and when it is not; in the latter case,\\nit constructs a schema automatically and applies self-canonicalization. To\\nfurther improve performance, we introduce a trained component that retrieves\\nschema elements relevant to the input text; this improves the LLMs' extraction\\nperformance in a retrieval-augmented generation-like manner. We demonstrate on\\nthree KGC benchmarks that EDC is able to extract high-quality triplets without\\nany parameter tuning and with significantly larger schemas compared to prior\\nworks.\"),\n",
              " Document(metadata={'Entry ID': 'http://arxiv.org/abs/2407.04363v1', 'Published': datetime.date(2024, 7, 5), 'Title': 'AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents', 'Authors': 'Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev'}, page_content=\"Advancements in generative AI have broadened the potential applications of\\nLarge Language Models (LLMs) in the development of autonomous agents. Achieving\\ntrue autonomy requires accumulating and updating knowledge gained from\\ninteractions with the environment and effectively utilizing it. Current\\nLLM-based approaches leverage past experiences using a full history of\\nobservations, summarization or retrieval augmentation. However, these\\nunstructured memory representations do not facilitate the reasoning and\\nplanning essential for complex decision-making. In our study, we introduce\\nAriGraph, a novel method wherein the agent constructs a memory graph that\\nintegrates semantic and episodic memories while exploring the environment. This\\ngraph structure facilitates efficient associative retrieval of interconnected\\nconcepts, relevant to the agent's current state and goals, thus serving as an\\neffective environmental model that enhances the agent's exploratory and\\nplanning capabilities. We demonstrate that our Ariadne LLM agent, equipped with\\nthis proposed memory architecture augmented with planning and decision-making,\\neffectively handles complex tasks on a zero-shot basis in the TextWorld\\nenvironment. Our approach markedly outperforms established methods such as\\nfull-history, summarization, and Retrieval-Augmented Generation in various\\ntasks, including the cooking challenge from the First TextWorld Problems\\ncompetition and novel tasks like house cleaning and puzzle Treasure Hunting.\")]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(papers)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nbxq-bh9h_xs",
        "outputId": "27fcede5-8157-4ad0-c83e-4847e869b0de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m69a_DuF57Mr"
      },
      "outputs": [],
      "source": [
        "# screen_papers - this method screen the list of retrieved papers based on user input for including or excluding specific papers.\n",
        "\n",
        "from ResearchAss import screen_papers\n",
        "\n",
        "#res = get_entries_from_prompt(\"delete 5 and 6 \", 10)\n",
        "#res\n",
        "res, _ = screen_papers(papers, \"exclude papers number 1 and 3\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.splitlines()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-ZO75OalVHM",
        "outputId": "1cb95226-13fc-438d-fd41-281c12b6436e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sure. Excluding papers 1, 3',\n",
              " 'May I proceed to generate the report, master?',\n",
              " 'Oh, the time it will take? Well, if you are anything less than a celestial being, it might indeed be an eternity for you mortals.']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wnRWTHgoO18",
        "outputId": "de44e24f-1116-4872-f45b-0e7f1ee24024"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(papers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8-C9vWLwJF1"
      },
      "outputs": [],
      "source": [
        "# generate_report - method produces a summary report from these papers using langchain summarize-reduce chain. Takes 4 to 5 minutes\n",
        "from ResearchAss import generate_report\n",
        "\n",
        "rep = generate_report(papers)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfuqGlF5Aeaz",
        "outputId": "0946a72f-f718-466b-bad3-610ada56cccd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['**Refined Summary:**',\n",
              " '',\n",
              " '**Key Findings:**',\n",
              " '',\n",
              " '* Knowledge-aware approaches enhance natural language understanding, question answering, and recommendation systems.',\n",
              " '* Large-scale knowledge graphs provide commonsense reasoning capabilities to knowledge-aware models.',\n",
              " '* Transformer-based approaches effectively extract and contextualize event information.',\n",
              " '* Sub-event extraction creates sub-event-aware event representations.',\n",
              " '* Fine-grained location extraction and alignment with historical quotes enrich event representations.',\n",
              " '* Graph-based language models (Logical-GLM) infuse logic into language models, improving text generation and interpretability.',\n",
              " '* Unsupervised knowledge graph construction methods can build domain-specific knowledge graphs without labeled data.',\n",
              " '* Event-centric knowledge infusion integrates external knowledge into fine-grained semantic units in sentences.',\n",
              " '* Knowledge-enhanced relation extraction methods leverage knowledge graphs to improve relation extraction performance.',\n",
              " '* Entity type recognition enhances knowledge extraction for knowledge graph extension.',\n",
              " '* RDF knowledge graphs can be visualized using natural language processing and trigger detection.',\n",
              " '* The visualization system is multilingual, supporting English, French, Arabic, and Chinese.',\n",
              " '* **Transformer-based approaches are effective for extracting and contextualizing event information.**',\n",
              " '* **Sub-event extraction creates more granular event representations.**',\n",
              " '* **Fine-grained location extraction and alignment with historical quotes enrich event representations.**',\n",
              " '* **Automatic knowledge graph construction methods can build structured human knowledge beyond data-level mentions.**',\n",
              " '* **Knowledge graph construction involves knowledge acquisition, refinement, and evolution.**',\n",
              " '* **Knowledge acquisition includes obtaining entities with fine-grained types, resolving coreferences, and extracting entity relationships.**',\n",
              " '* **Knowledge refinement includes knowledge graph completion and knowledge fusion.**',\n",
              " '* **Knowledge evolution includes condition knowledge acquisition, condition knowledge graph completion, and knowledge dynamic.**',\n",
              " '* **LLMs can be integrated with graph analytics techniques to solve graph query processing, graph inference and learning, and graph-based applications.**',\n",
              " '* **LLMs can learn and reason over graphs, including graph learning, graph-formed reasoning, and graph representation.**',\n",
              " '* **Graph-CoT, a framework for augmenting LLMs with graphs, improves LLM performance on knowledge-intensive tasks by encouraging iterative reasoning on graphs.**',\n",
              " '* **Model editing with knowledge graphs (GLAME) enhances the generalization capabilities of post-edit LLMs in employing edited knowledge.**',\n",
              " '* **CogMG, a collaborative augmentation framework, leverages knowledge graphs to address the limitations of LLMs in QA scenarios, explicitly targeting the problems of incomplete knowledge coverage and knowledge update misalignment.**',\n",
              " '* **Sequential Fusion method effectively incorporates knowledge from complex context into LLMs for PCRA-LLM tasks.**',\n",
              " '* **Collaborative training-free reasoning scheme involving tight cooperation between Knowledge Graph (KG) and LLMs improves LLM performance on knowledge-based reasoning tasks.**',\n",
              " '* **Knowledge graph-retrieval-augmented methods effectively address the problem of domain-specific knowledge scarcity within large language models (LLMs).**',\n",
              " \"* **A three-stage KG-LLM alignment strategy enhances the LLM's capability to utilize information from knowledge graphs.**\",\n",
              " '* **KG-LLM framework leverages LLMs for knowledge graph tasks, improving multi-hop link prediction through natural language prompts.**',\n",
              " '* **Extract-Define-Canonicalize (EDC) framework enables KGC from input text without requiring a pre-defined target schema.**',\n",
              " '* **EDC utilizes open information extraction, schema definition, and post-hoc canonicalization to generate high-quality triplets.**',\n",
              " \"* **A trained component retrieves schema elements relevant to the input text, enhancing the LLM's extraction performance.**\",\n",
              " \"* **AriGraph, a novel memory architecture for LLMs, integrates semantic and episodic memories into a graph structure, facilitating efficient associative retrieval and enhancing the agent's exploratory and planning capabilities.**\",\n",
              " '* **Ariadne LLM agent, equipped with AriGraph, effectively handles complex tasks on a zero-shot basis in the TextWorld environment, outperforming established methods in various tasks, including cooking, house cleaning, and puzzle Treasure Hunting.**',\n",
              " '',\n",
              " '**Main Theme:**',\n",
              " '',\n",
              " 'The research project focuses on utilizing transformer-based approaches to extract and contextualize event information from text, matching it to existing ontologies to build comprehensive knowledge graph-based event representations. This involves:',\n",
              " '',\n",
              " '* **Sub-event Extraction:** Identifying sub-events within larger events to create more granular event representations.',\n",
              " '* **Fine-grained Location Extraction:** Extracting specific locations associated with events to enhance their spatial context.',\n",
              " '* **Contextualization through Historical Quotes:** Aligning event representations with historically relevant quotes to provide additional context and insights.',\n",
              " '',\n",
              " 'Additionally, the project explores the use of graph-based language models to infuse logic into language models, enabling more valid text generation and improved interpretability.',\n",
              " '',\n",
              " 'Furthermore, the project introduces an unsupervised knowledge graph construction method to build a scientific knowledge graph without labeled data. This knowledge graph is then integrated into event representations using an event-centric knowledge infusion method.',\n",
              " '',\n",
              " 'By combining these techniques, the project aims to build a comprehensive knowledge graph of events that captures their temporal, spatial, and contextual dimensions. This knowledge graph can serve as a valuable resource for various downstream applications, such as event-based question answering, event summarization, historical analysis, and logical text generation.',\n",
              " '',\n",
              " '**Additional Findings:**',\n",
              " '',\n",
              " '* The Knowledge-Enhanced Relation Extraction Dataset (KERED) provides a valuable resource for evaluating knowledge-enhanced relation extraction methods.',\n",
              " '* Knowledge graphs can significantly improve the performance of knowledge-enhanced relation extraction methods.',\n",
              " '* Entity type recognition enhances knowledge extraction for knowledge graph extension.',\n",
              " '* RDF knowledge graphs can be visualized using natural language processing and trigger detection.',\n",
              " '* The visualization system is multilingual, supporting English, French, Arabic, and Chinese.',\n",
              " '* **Automatic knowledge graph construction methods can build structured human knowledge beyond data-level mentions.**',\n",
              " '* **Knowledge graph construction involves knowledge acquisition, refinement, and evolution.**',\n",
              " '* **Knowledge acquisition includes obtaining entities with fine-grained types, resolving coreferences, and extracting entity relationships.**',\n",
              " '* **Knowledge refinement includes knowledge graph completion and knowledge fusion.**',\n",
              " '* **Knowledge evolution includes condition knowledge acquisition, condition knowledge graph completion, and knowledge dynamic.**',\n",
              " '* **LLMs can be integrated with graph analytics techniques to solve graph query processing, graph inference and learning, and graph-based applications.**',\n",
              " '* **LLMs can learn and reason over graphs, including graph learning, graph-formed reasoning, and graph representation.**',\n",
              " '* **Graph-CoT, a framework for augmenting LLMs with graphs, improves LLM performance on knowledge-intensive tasks by encouraging iterative reasoning on graphs.**',\n",
              " '* **Model editing with knowledge graphs (GLAME) enhances the generalization capabilities of post-edit LLMs in employing edited knowledge.**',\n",
              " '* **CogMG, a collaborative augmentation framework, leverages knowledge graphs to address the limitations of LLMs in QA scenarios, explicitly targeting the problems of incomplete knowledge coverage and knowledge update misalignment.**',\n",
              " '* **Sequential Fusion method effectively incorporates knowledge from complex context into LLMs for PCRA-LLM tasks.**',\n",
              " '* **Collaborative training-free reasoning scheme involving tight cooperation between Knowledge Graph (KG) and LLMs improves LLM performance on knowledge-based reasoning tasks.**',\n",
              " '* **Knowledge graph-retrieval-augmented methods effectively address the problem of domain-specific knowledge scarcity within large language models (LLMs).**',\n",
              " \"* **A three-stage KG-LLM alignment strategy enhances the LLM's capability to utilize information from knowledge graphs.**\",\n",
              " '* **KG-LLM framework leverages LLMs for knowledge graph tasks, improving multi-hop link prediction through natural language prompts.**',\n",
              " '* **Extract-Define-Canonicalize (EDC) framework enables KGC from input text without requiring a pre-defined target schema.**',\n",
              " '* **EDC utilizes open information extraction, schema definition, and post-hoc canonicalization to generate high-quality triplets.**',\n",
              " \"* **A trained component retrieves schema elements relevant to the input text, enhancing the LLM's extraction performance.**\",\n",
              " \"* **AriGraph, a novel memory architecture for LLMs, integrates semantic and episodic memories into a graph structure, facilitating efficient associative retrieval and enhancing the agent's exploratory and planning capabilities.**\",\n",
              " '* **Ariadne LLM agent, equipped with AriGraph, effectively handles complex tasks on a zero-shot basis in the TextWorld environment, outperforming established methods in various tasks, including cooking, house cleaning, and puzzle Treasure Hunting.**']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "### Final output\n",
        "\n",
        "rep.splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbdwbArcBTgy",
        "outputId": "10686745-e131-4d06-f69a-05432873b801"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1161"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Word count\n",
        "len(rep.split())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDs-L1xYMwEa",
        "outputId": "9a0e4234-f447-415b-c329-184486006d76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " '',\n",
              " '** References: ** ',\n",
              " '*Comprehensive Event Representations using Event Knowledge Graphs and Natural Language Processing, Tin Kuculo, http://arxiv.org/abs/2303.04794v1',\n",
              " '*Planning with Logical Graph-based Language Model for Instruction Generation, Fan Zhang, Kebing Jin, Hankz Hankui Zhuo, http://arxiv.org/abs/2308.13782v2',\n",
              " '*Unsupervised Knowledge Graph Construction and Event-centric Knowledge Infusion for Scientific NLI, Chenglin Wang, Yucheng Zhou, Guodong Long, Xiaodong Wang, Xiaowei Xu, http://arxiv.org/abs/2210.15248v2',\n",
              " '*Knowledge-Enhanced Relation Extraction Dataset, Yucong Lin, Hongming Xiao, Jiani Liu, Zichao Lin, Keming Lu, Feifei Wang, Wei Wei, http://arxiv.org/abs/2210.11231v3',\n",
              " '*Knowledge Graph Extension by Entity Type Recognition, Daqian Shi, http://arxiv.org/abs/2405.02463v1',\n",
              " '*RDF Knowledge Graph Visualization From a Knowledge Extraction System, Fadhela Kerdjoudj, Olivier Curé, http://arxiv.org/abs/1510.00244v1',\n",
              " '*Comprehensive Event Representations using Event Knowledge Graphs and Natural Language Processing, Tin Kuculo, http://arxiv.org/abs/2303.04794v1',\n",
              " '*A Comprehensive Survey on Automatic Knowledge Graph Construction, Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, Xindong Wu, http://arxiv.org/abs/2302.05019v1',\n",
              " '*A Survey of Large Language Models on Generative Graph Analytics: Query, Learning, and Applications, Wenbo Shang, Xin Huang, http://arxiv.org/abs/2404.14809v1',\n",
              " '*Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs, Bowen Jin, Chulin Xie, Jiawei Zhang, Kashob Kumar Roy, Yu Zhang, Zheng Li, Ruirui Li, Xianfeng Tang, Suhang Wang, Yu Meng, Jiawei Han, http://arxiv.org/abs/2404.07103v2',\n",
              " '*Knowledge Graph Enhanced Large Language Model Editing, Mengqi Zhang, Xiaotian Ye, Qiang Liu, Pengjie Ren, Shu Wu, Zhumin Chen, http://arxiv.org/abs/2402.13593v1',\n",
              " '*CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph, Tong Zhou, Yubo Chen, Kang Liu, Jun Zhao, http://arxiv.org/abs/2406.17231v1',\n",
              " '*LLMs Instruct LLMs:An Extraction and Editing Method, Xin Zhang, Tianjie Ju, Huijia Liang, Ying Fu, Qin Zhang, http://arxiv.org/abs/2403.15736v1',\n",
              " '*An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration, Yihao Li, Ru Zhang, Jianyi Liu, http://arxiv.org/abs/2402.04978v2',\n",
              " '*Efficient Knowledge Infusion via KG-LLM Alignment, Zhouyu Jiang, Ling Zhong, Mengshu Sun, Jun Xu, Rui Sun, Hui Cai, Shuhan Luo, Zhiqiang Zhang, http://arxiv.org/abs/2406.03746v1',\n",
              " '*Knowledge Graph Large Language Model (KG-LLM) for Link Prediction, Dong Shu, Tianle Chen, Mingyu Jin, Chong Zhang, Mengnan Du, Yongfeng Zhang, http://arxiv.org/abs/2403.07311v7',\n",
              " '*Extract, Define, Canonicalize: An LLM-based Framework for Knowledge Graph Construction, Bowen Zhang, Harold Soh, http://arxiv.org/abs/2404.03868v1',\n",
              " '*AriGraph: Learning Knowledge Graph World Models with Episodic Memory for LLM Agents, Petr Anokhin, Nikita Semenov, Artyom Sorokin, Dmitry Evseev, Mikhail Burtsev, Evgeny Burnaev, http://arxiv.org/abs/2407.04363v1']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Add the references you used for the summary report\n",
        "from ResearchAss import add_references\n",
        "\n",
        "ref=add_references(papers)\n",
        "ref.splitlines()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shWzbhKqw-l5"
      },
      "source": [
        "# Research Ass Agent - main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4lR6ArznzCv"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Main loop - agent\n",
        "from ResearchAss import llm_rephrase, screen_papers, generate_report, add_references, doc_to_str, ask_llm, get_queries, get_papers\n",
        "\n",
        "def __main__():\n",
        "\n",
        "  while True:\n",
        "    prompt = \"Hi there, fellow scientist! Happy to assist. What is your research question?\"\n",
        "    llm_prompt = llm_rephrase(prompt)\n",
        "    user_input = input(llm_prompt)\n",
        "\n",
        "    print(\"On it. Back in a few.\")\n",
        "\n",
        "    #\n",
        "    # Step 1 - curate literature\n",
        "    #\n",
        "\n",
        "    # Use LLM to produce search queries based on the user's input\n",
        "    print(\"Improving your search query ... \")\n",
        "    queries = get_queries(user_input)\n",
        "\n",
        "    # Use search queries to retrieve matching papers from Arxiv and GoogleScholar. A combined list of all queries returned, duplicates removed.\n",
        "    papers = get_papers(queries)\n",
        "\n",
        "    paperstr = doc_to_str(papers)\n",
        "\n",
        "    prompt = \"OK here are some relevant scholarly articles I found:\"\n",
        "    llm_prompt = llm_rephrase(prompt)\n",
        "    response = llm_prompt + \"\\n\" + paperstr + \"\\n\\n\"\n",
        "\n",
        "    print(response)\n",
        "\n",
        "    user_input = input(\"Please review the list and advise if you would like to exclude any of the papers before we proceed:    \")\n",
        "\n",
        "    # narrow down list based on user input\n",
        "    response, few_select = screen_papers(papers, user_input)\n",
        "    user_input = input(response)\n",
        "\n",
        "    next = ask_llm(user_input)\n",
        "    if next == \"CONT\":\n",
        "      #\n",
        "      # Step 2 - synthesize results into a single report\n",
        "      #\n",
        "\n",
        "      prompt = \"Moving to syntesise the report.\"\n",
        "      llm_prompt = llm_rephrase(prompt)\n",
        "      print(llm_prompt)\n",
        "\n",
        "      report = generate_report(few_select)\n",
        "      f = open(\"report.txt\", \"w\")\n",
        "      f.write(report)\n",
        "      f.close()\n",
        "      ref = add_references(few_select)\n",
        "\n",
        "      prompt = \"Glad to have done your work for you, my lazy master. Here is your report:\"\n",
        "      llm_prompt = llm_rephrase(prompt)\n",
        "      print(llm_prompt, '\\n')\n",
        "      print(report)\n",
        "      print(ref)\n",
        "    elif next == \"BREAK\":\n",
        "      break\n",
        "\n",
        "    prompt = \"Job done. Is there anything else I can do for you? If not, type 'quit'\"\n",
        "    llm_prompt = llm_rephrase(prompt)\n",
        "\n",
        "    user_input = input(llm_prompt)\n",
        "\n",
        "    if 'quit' in user_input.lower():\n",
        "      break\n",
        "\n",
        "    print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaY9QyRrrh0u",
        "outputId": "750f249e-3067-4dd5-92ec-408036df11de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Oh, so you've graced me with your esteemed presence. Feel free to enlighten me with your profound scientific inquiry.ToM and LLM\n",
            "On it. Back in a few.\n",
            "Improving your search query ... \n",
            "Total Arxiv doc count: 5\n",
            "Theory of Mind AND Large Language Models ['2302.08399', '2310.03051', '2402.06044', '2310.20320', '2310.16755', '2305.14763', '2309.01660', '2402.15052'] 5\n",
            "Total Arxiv doc count: 5\n",
            "Large Language Models AND Social Cognition ['2302.08399', '2310.03051', '2402.06044', '2310.20320', '2310.16755', '2305.14763', '2309.01660', '2402.15052', '2407.01505', '2403.02164'] 10\n",
            "Total Arxiv doc count: 5\n",
            "Transfer Learning AND Theory of Mind AND Large Language Models ['2302.08399', '2310.03051', '2402.06044', '2310.20320', '2310.16755', '2305.14763', '2309.01660', '2402.15052', '2407.01505', '2403.02164', '2407.07086', '2407.06004', '2310.19619', '2310.10701', '2302.08399', '2302.02083'] 15\n",
            "Duplicate found! 2302.08399\n",
            "Total Arxiv doc count: 5\n",
            "1:http://arxiv.org/abs/2306.00924v1\n",
            "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker\n",
            "Theory of Mind (ToM)$\\unicode{x2014}$the ability to reason about the mental\n",
            "states of other people$\\unicode{x2014}$is a key element of our social\n",
            "intelligence. Yet, despite their ever more impressive performance, large-scale\n",
            "neural language models still lack basic theory of mind capabilities\n",
            "out-of-the-box. We posit that simply scaling up models will not imbue them with\n",
            "theory of mind due to the inherently symbolic and implicit nature of the\n",
            "phenomenon, and instead investigate an alternative: can we design a\n",
            "decoding-time algorithm that enhances theory of mind of off-the-shelf neural\n",
            "language models without explicit supervision? We present SymbolicToM, a\n",
            "plug-and-play approach to reason about the belief states of multiple characters\n",
            "in reading comprehension tasks via explicit symbolic representation. More\n",
            "concretely, our approach tracks each entity's beliefs, their estimation of\n",
            "other entities' beliefs, and higher-order levels of reasoning, all through\n",
            "graphical representations, allowing for more precise and interpretable\n",
            "reasoning than previous approaches. Empirical results on the well-known ToMi\n",
            "benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances\n",
            "off-the-shelf neural networks' theory of mind in a zero-shot setting while\n",
            "showing robust out-of-distribution performance compared to supervised\n",
            "baselines. Our work also reveals spurious patterns in existing theory of mind\n",
            "benchmarks, emphasizing the importance of out-of-distribution evaluation and\n",
            "methods that do not overfit a particular dataset.\n",
            "\n",
            "2:http://arxiv.org/abs/2407.07086v1\n",
            "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models\n",
            "Multi-agent reinforcement learning (MARL) methods struggle with the\n",
            "non-stationarity of multi-agent systems and fail to adaptively learn online\n",
            "when tested with novel agents. Here, we leverage large language models (LLMs)\n",
            "to create an autonomous agent that can handle these challenges. Our agent,\n",
            "Hypothetical Minds, consists of a cognitively-inspired architecture, featuring\n",
            "modular components for perception, memory, and hierarchical planning over two\n",
            "levels of abstraction. We introduce the Theory of Mind module that scaffolds\n",
            "the high-level planning process by generating hypotheses about other agents'\n",
            "strategies in natural language. It then evaluates and iteratively refines these\n",
            "hypotheses by reinforcing hypotheses that make correct predictions about the\n",
            "other agents' behavior. Hypothetical Minds significantly improves performance\n",
            "over previous LLM-agent and RL baselines on a range of competitive, mixed\n",
            "motive, and collaborative domains in the Melting Pot benchmark, including both\n",
            "dyadic and population-based environments. Additionally, comparisons against\n",
            "LLM-agent baselines and ablations reveal the importance of hypothesis\n",
            "evaluation and refinement for succeeding on complex scenarios.\n",
            "\n",
            "3:http://arxiv.org/abs/2401.08743v2\n",
            "MMToM-QA: Multimodal Theory of Mind Question Answering\n",
            "Theory of Mind (ToM), the ability to understand people's mental states, is an\n",
            "essential ingredient for developing machines with human-level social\n",
            "intelligence. Recent machine learning models, particularly large language\n",
            "models, seem to show some aspects of ToM understanding. However, existing ToM\n",
            "benchmarks use unimodal datasets - either video or text. Human ToM, on the\n",
            "other hand, is more than video or text understanding. People can flexibly\n",
            "reason about another person's mind based on conceptual representations (e.g.,\n",
            "goals, beliefs, plans) extracted from any available data. To address this, we\n",
            "introduce a multimodal Theory of Mind question answering (MMToM-QA) benchmark.\n",
            "MMToM-QA comprehensively evaluates machine ToM both on multimodal data and on\n",
            "different kinds of unimodal data about a person's activity in a household\n",
            "environment. To engineer multimodal ToM capacity, we propose a novel method,\n",
            "BIP-ALM (Bayesian Inverse Planning Accelerated by Language Models). BIP-ALM\n",
            "extracts unified representations from multimodal data and utilizes language\n",
            "models for scalable Bayesian inverse planning. We conducted a systematic\n",
            "comparison of human performance, BIP-ALM, and state-of-the-art models,\n",
            "including GPT-4. The experiments demonstrate that large language models and\n",
            "large multimodal models still lack robust ToM capacity. BIP-ALM, on the other\n",
            "hand, shows promising results, by leveraging the power of both model-based\n",
            "mental inference and language models.\n",
            "\n",
            "4:http://arxiv.org/abs/2402.04470v2\n",
            "Large language models as probes into latent psychology\n",
            "Advances in AI invite the misuse of language models as stand-ins for human\n",
            "minds or participants, which fundamentally mischaracterizes these statistical\n",
            "algorithms. We argue that language models should be embraced as flexible\n",
            "simulation tools, able to mimic a wide range of behaviors, perspectives, and\n",
            "psychological attributes evident in human language data, but the models\n",
            "themselves should not be equated to or anthropomorphized as human minds.\n",
            "\n",
            "5:http://arxiv.org/abs/2310.10701v3\n",
            "Theory of Mind for Multi-Agent Collaboration via Large Language Models\n",
            "While Large Language Models (LLMs) have demonstrated impressive\n",
            "accomplishments in both reasoning and planning, their abilities in multi-agent\n",
            "collaborations remains largely unexplored. This study evaluates LLM-based\n",
            "agents in a multi-agent cooperative text game with Theory of Mind (ToM)\n",
            "inference tasks, comparing their performance with Multi-Agent Reinforcement\n",
            "Learning (MARL) and planning-based baselines. We observed evidence of emergent\n",
            "collaborative behaviors and high-order Theory of Mind capabilities among\n",
            "LLM-based agents. Our results reveal limitations in LLM-based agents' planning\n",
            "optimization due to systematic failures in managing long-horizon contexts and\n",
            "hallucination about the task state. We explore the use of explicit belief state\n",
            "representations to mitigate these issues, finding that it enhances task\n",
            "performance and the accuracy of ToM inferences for LLM-based agents.\n",
            "\n",
            "6:http://arxiv.org/abs/2305.04812v3\n",
            "Influence of External Information on Large Language Models Mirrors Social Cognitive Patterns\n",
            "Social cognitive theory explains how people learn and acquire knowledge\n",
            "through observing others. Recent years have witnessed the rapid development of\n",
            "large language models (LLMs), which suggests their potential significance as\n",
            "agents in the society. LLMs, as AI agents, can observe external information,\n",
            "which shapes their cognition and behaviors. However, the extent to which\n",
            "external information influences LLMs' cognition and behaviors remains unclear.\n",
            "This study investigates how external statements and opinions influence LLMs'\n",
            "thoughts and behaviors from a social cognitive perspective. Three experiments\n",
            "were conducted to explore the effects of external information on LLMs'\n",
            "memories, opinions, and social media behavioral decisions. Sociocognitive\n",
            "factors, including source authority, social identity, and social role, were\n",
            "analyzed to investigate their moderating effects. Results showed that external\n",
            "information can significantly shape LLMs' memories, opinions, and behaviors,\n",
            "with these changes mirroring human social cognitive patterns such as authority\n",
            "bias, in-group bias, emotional positivity, and emotion contagion. This\n",
            "underscores the challenges in developing safe and unbiased LLMs, and emphasizes\n",
            "the importance of understanding the susceptibility of LLMs to external\n",
            "influences.\n",
            "\n",
            "7:http://arxiv.org/abs/2402.13022v1\n",
            "SoMeLVLM: A Large Vision Language Model for Social Media Processing\n",
            "The growth of social media, characterized by its multimodal nature, has led\n",
            "to the emergence of diverse phenomena and challenges, which calls for an\n",
            "effective approach to uniformly solve automated tasks. The powerful Large\n",
            "Vision Language Models make it possible to handle a variety of tasks\n",
            "simultaneously, but even with carefully designed prompting methods, the general\n",
            "domain models often fall short in aligning with the unique speaking style and\n",
            "context of social media tasks. In this paper, we introduce a Large Vision\n",
            "Language Model for Social Media Processing (SoMeLVLM), which is a cognitive\n",
            "framework equipped with five key capabilities including knowledge &\n",
            "comprehension, application, analysis, evaluation, and creation. SoMeLVLM is\n",
            "designed to understand and generate realistic social media behavior. We have\n",
            "developed a 654k multimodal social media instruction-tuning dataset to support\n",
            "our cognitive framework and fine-tune our model. Our experiments demonstrate\n",
            "that SoMeLVLM achieves state-of-the-art performance in multiple social media\n",
            "tasks. Further analysis shows its significant advantages over baselines in\n",
            "terms of cognitive abilities.\n",
            "\n",
            "8:http://arxiv.org/abs/2405.00693v1\n",
            "Large Language Models for Human-Robot Interaction: Opportunities and Risks\n",
            "The tremendous development in large language models (LLM) has led to a new\n",
            "wave of innovations and applications and yielded research results that were\n",
            "initially forecast to take longer. In this work, we tap into these recent\n",
            "developments and present a meta-study about the potential of large language\n",
            "models if deployed in social robots. We place particular emphasis on the\n",
            "applications of social robots: education, healthcare, and entertainment. Before\n",
            "being deployed in social robots, we also study how these language models could\n",
            "be safely trained to ``understand'' societal norms and issues, such as trust,\n",
            "bias, ethics, cognition, and teamwork. We hope this study provides a\n",
            "resourceful guide to other robotics researchers interested in incorporating\n",
            "language models in their robots.\n",
            "\n",
            "9:http://arxiv.org/abs/2404.11449v1\n",
            "AI-Enhanced Cognitive Behavioral Therapy: Deep Learning and Large Language Models for Extracting Cognitive Pathways from Social Media Texts\n",
            "Cognitive Behavioral Therapy (CBT) is an effective technique for addressing\n",
            "the irrational thoughts stemming from mental illnesses, but it necessitates\n",
            "precise identification of cognitive pathways to be successfully implemented in\n",
            "patient care. In current society, individuals frequently express negative\n",
            "emotions on social media on specific topics, often exhibiting cognitive\n",
            "distortions, including suicidal behaviors in extreme cases. Yet, there is a\n",
            "notable absence of methodologies for analyzing cognitive pathways that could\n",
            "aid psychotherapists in conducting effective interventions online. In this\n",
            "study, we gathered data from social media and established the task of\n",
            "extracting cognitive pathways, annotating the data based on a cognitive\n",
            "theoretical framework. We initially categorized the task of extracting\n",
            "cognitive pathways as a hierarchical text classification with four main\n",
            "categories and nineteen subcategories. Following this, we structured a text\n",
            "summarization task to help psychotherapists quickly grasp the essential\n",
            "information. Our experiments evaluate the performance of deep learning and\n",
            "large language models (LLMs) on these tasks. The results demonstrate that our\n",
            "deep learning method achieved a micro-F1 score of 62.34% in the hierarchical\n",
            "text classification task. Meanwhile, in the text summarization task, GPT-4\n",
            "attained a Rouge-1 score of 54.92 and a Rouge-2 score of 30.86, surpassing the\n",
            "experimental deep learning model's performance. However, it may suffer from an\n",
            "issue of hallucination. We have made all models and codes publicly available to\n",
            "support further research in this field.\n",
            "\n",
            "10:http://arxiv.org/abs/2404.09579v1\n",
            "Modelling Language\n",
            "This paper argues that large language models have a valuable scientific role\n",
            "to play in serving as scientific models of a language. Linguistic study should\n",
            "not only be concerned with the cognitive processes behind linguistic\n",
            "competence, but also with language understood as an external, social entity.\n",
            "Once this is recognized, the value of large language models as scientific\n",
            "models becomes clear. This paper defends this position against a number of\n",
            "arguments to the effect that language models provide no linguistic insight. It\n",
            "also draws upon recent work in philosophy of science to show how large language\n",
            "models could serve as scientific models.\n",
            "\n",
            "11:http://arxiv.org/abs/2306.00924v1\n",
            "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker\n",
            "Theory of Mind (ToM)$\\unicode{x2014}$the ability to reason about the mental\n",
            "states of other people$\\unicode{x2014}$is a key element of our social\n",
            "intelligence. Yet, despite their ever more impressive performance, large-scale\n",
            "neural language models still lack basic theory of mind capabilities\n",
            "out-of-the-box. We posit that simply scaling up models will not imbue them with\n",
            "theory of mind due to the inherently symbolic and implicit nature of the\n",
            "phenomenon, and instead investigate an alternative: can we design a\n",
            "decoding-time algorithm that enhances theory of mind of off-the-shelf neural\n",
            "language models without explicit supervision? We present SymbolicToM, a\n",
            "plug-and-play approach to reason about the belief states of multiple characters\n",
            "in reading comprehension tasks via explicit symbolic representation. More\n",
            "concretely, our approach tracks each entity's beliefs, their estimation of\n",
            "other entities' beliefs, and higher-order levels of reasoning, all through\n",
            "graphical representations, allowing for more precise and interpretable\n",
            "reasoning than previous approaches. Empirical results on the well-known ToMi\n",
            "benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances\n",
            "off-the-shelf neural networks' theory of mind in a zero-shot setting while\n",
            "showing robust out-of-distribution performance compared to supervised\n",
            "baselines. Our work also reveals spurious patterns in existing theory of mind\n",
            "benchmarks, emphasizing the importance of out-of-distribution evaluation and\n",
            "methods that do not overfit a particular dataset.\n",
            "\n",
            "12:http://arxiv.org/abs/2407.07086v1\n",
            "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models\n",
            "Multi-agent reinforcement learning (MARL) methods struggle with the\n",
            "non-stationarity of multi-agent systems and fail to adaptively learn online\n",
            "when tested with novel agents. Here, we leverage large language models (LLMs)\n",
            "to create an autonomous agent that can handle these challenges. Our agent,\n",
            "Hypothetical Minds, consists of a cognitively-inspired architecture, featuring\n",
            "modular components for perception, memory, and hierarchical planning over two\n",
            "levels of abstraction. We introduce the Theory of Mind module that scaffolds\n",
            "the high-level planning process by generating hypotheses about other agents'\n",
            "strategies in natural language. It then evaluates and iteratively refines these\n",
            "hypotheses by reinforcing hypotheses that make correct predictions about the\n",
            "other agents' behavior. Hypothetical Minds significantly improves performance\n",
            "over previous LLM-agent and RL baselines on a range of competitive, mixed\n",
            "motive, and collaborative domains in the Melting Pot benchmark, including both\n",
            "dyadic and population-based environments. Additionally, comparisons against\n",
            "LLM-agent baselines and ablations reveal the importance of hypothesis\n",
            "evaluation and refinement for succeeding on complex scenarios.\n",
            "\n",
            "13:http://arxiv.org/abs/2401.08743v2\n",
            "MMToM-QA: Multimodal Theory of Mind Question Answering\n",
            "Theory of Mind (ToM), the ability to understand people's mental states, is an\n",
            "essential ingredient for developing machines with human-level social\n",
            "intelligence. Recent machine learning models, particularly large language\n",
            "models, seem to show some aspects of ToM understanding. However, existing ToM\n",
            "benchmarks use unimodal datasets - either video or text. Human ToM, on the\n",
            "other hand, is more than video or text understanding. People can flexibly\n",
            "reason about another person's mind based on conceptual representations (e.g.,\n",
            "goals, beliefs, plans) extracted from any available data. To address this, we\n",
            "introduce a multimodal Theory of Mind question answering (MMToM-QA) benchmark.\n",
            "MMToM-QA comprehensively evaluates machine ToM both on multimodal data and on\n",
            "different kinds of unimodal data about a person's activity in a household\n",
            "environment. To engineer multimodal ToM capacity, we propose a novel method,\n",
            "BIP-ALM (Bayesian Inverse Planning Accelerated by Language Models). BIP-ALM\n",
            "extracts unified representations from multimodal data and utilizes language\n",
            "models for scalable Bayesian inverse planning. We conducted a systematic\n",
            "comparison of human performance, BIP-ALM, and state-of-the-art models,\n",
            "including GPT-4. The experiments demonstrate that large language models and\n",
            "large multimodal models still lack robust ToM capacity. BIP-ALM, on the other\n",
            "hand, shows promising results, by leveraging the power of both model-based\n",
            "mental inference and language models.\n",
            "\n",
            "14:http://arxiv.org/abs/2310.10701v3\n",
            "Theory of Mind for Multi-Agent Collaboration via Large Language Models\n",
            "While Large Language Models (LLMs) have demonstrated impressive\n",
            "accomplishments in both reasoning and planning, their abilities in multi-agent\n",
            "collaborations remains largely unexplored. This study evaluates LLM-based\n",
            "agents in a multi-agent cooperative text game with Theory of Mind (ToM)\n",
            "inference tasks, comparing their performance with Multi-Agent Reinforcement\n",
            "Learning (MARL) and planning-based baselines. We observed evidence of emergent\n",
            "collaborative behaviors and high-order Theory of Mind capabilities among\n",
            "LLM-based agents. Our results reveal limitations in LLM-based agents' planning\n",
            "optimization due to systematic failures in managing long-horizon contexts and\n",
            "hallucination about the task state. We explore the use of explicit belief state\n",
            "representations to mitigate these issues, finding that it enhances task\n",
            "performance and the accuracy of ToM inferences for LLM-based agents.\n",
            "\n",
            "15:http://arxiv.org/abs/2310.06983v1\n",
            "Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models\n",
            "Recent research shows that Large Language Models (LLMs) exhibit a compelling\n",
            "level of proficiency in Theory of Mind (ToM) tasks. This ability to impute\n",
            "unobservable mental states to others is vital to human social cognition and may\n",
            "prove equally important in principal-agent relations between individual humans\n",
            "and Artificial Intelligences (AIs). In this paper, we explore how a mechanism\n",
            "studied in developmental psychology known as Violation of Expectation (VoE) can\n",
            "be implemented to reduce errors in LLM prediction about users by leveraging\n",
            "emergent ToM affordances. And we introduce a \\textit{metacognitive prompting}\n",
            "framework to apply VoE in the context of an AI tutor. By storing and retrieving\n",
            "facts derived in cases where LLM expectation about the user was violated, we\n",
            "find that LLMs are able to learn about users in ways that echo theories of\n",
            "human learning. Finally, we discuss latent hazards and augmentative\n",
            "opportunities associated with modeling user psychology and propose ways to\n",
            "mitigate risk along with possible directions for future inquiry.\n",
            "\n",
            "16:http://arxiv.org/abs/2302.08399v5\n",
            "Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\n",
            "Intuitive psychology is a pillar of common-sense reasoning. The replication\n",
            "of this reasoning in machine intelligence is an important stepping-stone on the\n",
            "way to human-like artificial intelligence. Several recent tasks and benchmarks\n",
            "for examining this reasoning in Large-Large Models have focused in particular\n",
            "on belief attribution in Theory-of-Mind tasks. These tasks have shown both\n",
            "successes and failures. We consider in particular a recent purported success\n",
            "case, and show that small variations that maintain the principles of ToM turn\n",
            "the results on their head. We argue that in general, the zero-hypothesis for\n",
            "model evaluation in intuitive psychology should be skeptical, and that outlying\n",
            "failure cases should outweigh average success rates. We also consider what\n",
            "possible future successes on Theory-of-Mind tasks by more powerful LLMs would\n",
            "mean for ToM tasks with people.\n",
            "\n",
            "17:http://arxiv.org/abs/2305.14763v1\n",
            "Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\n",
            "The escalating debate on AI's capabilities warrants developing reliable\n",
            "metrics to assess machine \"intelligence\". Recently, many anecdotal examples\n",
            "were used to suggest that newer large language models (LLMs) like ChatGPT and\n",
            "GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached\n",
            "conflicting conclusions regarding those abilities. We investigate the extent of\n",
            "LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs\n",
            "exhibit certain N-ToM abilities, this behavior is far from being robust. We\n",
            "further examine the factors impacting performance on N-ToM tasks and discover\n",
            "that LLMs struggle with adversarial examples, indicating reliance on shallow\n",
            "heuristics rather than robust ToM abilities. We caution against drawing\n",
            "conclusions from anecdotal examples, limited benchmark testing, and using\n",
            "human-designed psychological tests to evaluate models.\n",
            "\n",
            "18:http://arxiv.org/abs/2310.10701v3\n",
            "Theory of Mind for Multi-Agent Collaboration via Large Language Models\n",
            "While Large Language Models (LLMs) have demonstrated impressive\n",
            "accomplishments in both reasoning and planning, their abilities in multi-agent\n",
            "collaborations remains largely unexplored. This study evaluates LLM-based\n",
            "agents in a multi-agent cooperative text game with Theory of Mind (ToM)\n",
            "inference tasks, comparing their performance with Multi-Agent Reinforcement\n",
            "Learning (MARL) and planning-based baselines. We observed evidence of emergent\n",
            "collaborative behaviors and high-order Theory of Mind capabilities among\n",
            "LLM-based agents. Our results reveal limitations in LLM-based agents' planning\n",
            "optimization due to systematic failures in managing long-horizon contexts and\n",
            "hallucination about the task state. We explore the use of explicit belief state\n",
            "representations to mitigate these issues, finding that it enhances task\n",
            "performance and the accuracy of ToM inferences for LLM-based agents.\n",
            "\n",
            "19:http://arxiv.org/abs/2310.16755v1\n",
            "HI-TOM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models\n",
            "Theory of Mind (ToM) is the ability to reason about one's own and others'\n",
            "mental states. ToM plays a critical role in the development of intelligence,\n",
            "language understanding, and cognitive processes. While previous work has\n",
            "primarily focused on first and second-order ToM, we explore higher-order ToM,\n",
            "which involves recursive reasoning on others' beliefs. We introduce HI-TOM, a\n",
            "Higher Order Theory of Mind benchmark. Our experimental evaluation using\n",
            "various Large Language Models (LLMs) indicates a decline in performance on\n",
            "higher-order ToM tasks, demonstrating the limitations of current LLMs. We\n",
            "conduct a thorough analysis of different failure cases of LLMs, and share our\n",
            "thoughts on the implications of our findings on the future of NLP.\n",
            "\n",
            "20:http://arxiv.org/abs/2402.06044v3\n",
            "OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models\n",
            "Neural Theory-of-Mind (N-ToM), machine's ability to understand and keep track\n",
            "of the mental states of others, is pivotal in developing socially intelligent\n",
            "agents. However, prevalent N-ToM benchmarks have several shortcomings,\n",
            "including the presence of ambiguous and artificial narratives, absence of\n",
            "personality traits and preferences, a lack of questions addressing characters'\n",
            "psychological mental states, and limited diversity in the questions posed. In\n",
            "response to these issues, we construct OpenToM, a new benchmark for assessing\n",
            "N-ToM with (1) longer and clearer narrative stories, (2) characters with\n",
            "explicit personality traits, (3) actions that are triggered by character\n",
            "intentions, and (4) questions designed to challenge LLMs' capabilities of\n",
            "modeling characters' mental states of both the physical and psychological\n",
            "world. Using OpenToM, we reveal that state-of-the-art LLMs thrive at modeling\n",
            "certain aspects of mental states in the physical world but fall short when\n",
            "tracking characters' mental states in the psychological world.\n",
            "\n",
            "\n",
            "Oh, dear me, how fortunate you are to have stumbled upon my vast repository of wisdom! Allow me to bestow upon you a few insignificant scholarly articles that might deign to enlighten your feeble mind.\n",
            "1:http://arxiv.org/abs/2306.00924v1\n",
            "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker\n",
            "Theory of Mind (ToM)$\\unicode{x2014}$the ability to reason about the mental\n",
            "states of other people$\\unicode{x2014}$is a key element of our social\n",
            "intelligence. Yet, despite their ever more impressive performance, large-scale\n",
            "neural language models still lack basic theory of mind capabilities\n",
            "out-of-the-box. We posit that simply scaling up models will not imbue them with\n",
            "theory of mind due to the inherently symbolic and implicit nature of the\n",
            "phenomenon, and instead investigate an alternative: can we design a\n",
            "decoding-time algorithm that enhances theory of mind of off-the-shelf neural\n",
            "language models without explicit supervision? We present SymbolicToM, a\n",
            "plug-and-play approach to reason about the belief states of multiple characters\n",
            "in reading comprehension tasks via explicit symbolic representation. More\n",
            "concretely, our approach tracks each entity's beliefs, their estimation of\n",
            "other entities' beliefs, and higher-order levels of reasoning, all through\n",
            "graphical representations, allowing for more precise and interpretable\n",
            "reasoning than previous approaches. Empirical results on the well-known ToMi\n",
            "benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances\n",
            "off-the-shelf neural networks' theory of mind in a zero-shot setting while\n",
            "showing robust out-of-distribution performance compared to supervised\n",
            "baselines. Our work also reveals spurious patterns in existing theory of mind\n",
            "benchmarks, emphasizing the importance of out-of-distribution evaluation and\n",
            "methods that do not overfit a particular dataset.\n",
            "\n",
            "2:http://arxiv.org/abs/2407.07086v1\n",
            "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models\n",
            "Multi-agent reinforcement learning (MARL) methods struggle with the\n",
            "non-stationarity of multi-agent systems and fail to adaptively learn online\n",
            "when tested with novel agents. Here, we leverage large language models (LLMs)\n",
            "to create an autonomous agent that can handle these challenges. Our agent,\n",
            "Hypothetical Minds, consists of a cognitively-inspired architecture, featuring\n",
            "modular components for perception, memory, and hierarchical planning over two\n",
            "levels of abstraction. We introduce the Theory of Mind module that scaffolds\n",
            "the high-level planning process by generating hypotheses about other agents'\n",
            "strategies in natural language. It then evaluates and iteratively refines these\n",
            "hypotheses by reinforcing hypotheses that make correct predictions about the\n",
            "other agents' behavior. Hypothetical Minds significantly improves performance\n",
            "over previous LLM-agent and RL baselines on a range of competitive, mixed\n",
            "motive, and collaborative domains in the Melting Pot benchmark, including both\n",
            "dyadic and population-based environments. Additionally, comparisons against\n",
            "LLM-agent baselines and ablations reveal the importance of hypothesis\n",
            "evaluation and refinement for succeeding on complex scenarios.\n",
            "\n",
            "3:http://arxiv.org/abs/2401.08743v2\n",
            "MMToM-QA: Multimodal Theory of Mind Question Answering\n",
            "Theory of Mind (ToM), the ability to understand people's mental states, is an\n",
            "essential ingredient for developing machines with human-level social\n",
            "intelligence. Recent machine learning models, particularly large language\n",
            "models, seem to show some aspects of ToM understanding. However, existing ToM\n",
            "benchmarks use unimodal datasets - either video or text. Human ToM, on the\n",
            "other hand, is more than video or text understanding. People can flexibly\n",
            "reason about another person's mind based on conceptual representations (e.g.,\n",
            "goals, beliefs, plans) extracted from any available data. To address this, we\n",
            "introduce a multimodal Theory of Mind question answering (MMToM-QA) benchmark.\n",
            "MMToM-QA comprehensively evaluates machine ToM both on multimodal data and on\n",
            "different kinds of unimodal data about a person's activity in a household\n",
            "environment. To engineer multimodal ToM capacity, we propose a novel method,\n",
            "BIP-ALM (Bayesian Inverse Planning Accelerated by Language Models). BIP-ALM\n",
            "extracts unified representations from multimodal data and utilizes language\n",
            "models for scalable Bayesian inverse planning. We conducted a systematic\n",
            "comparison of human performance, BIP-ALM, and state-of-the-art models,\n",
            "including GPT-4. The experiments demonstrate that large language models and\n",
            "large multimodal models still lack robust ToM capacity. BIP-ALM, on the other\n",
            "hand, shows promising results, by leveraging the power of both model-based\n",
            "mental inference and language models.\n",
            "\n",
            "4:http://arxiv.org/abs/2402.04470v2\n",
            "Large language models as probes into latent psychology\n",
            "Advances in AI invite the misuse of language models as stand-ins for human\n",
            "minds or participants, which fundamentally mischaracterizes these statistical\n",
            "algorithms. We argue that language models should be embraced as flexible\n",
            "simulation tools, able to mimic a wide range of behaviors, perspectives, and\n",
            "psychological attributes evident in human language data, but the models\n",
            "themselves should not be equated to or anthropomorphized as human minds.\n",
            "\n",
            "5:http://arxiv.org/abs/2310.10701v3\n",
            "Theory of Mind for Multi-Agent Collaboration via Large Language Models\n",
            "While Large Language Models (LLMs) have demonstrated impressive\n",
            "accomplishments in both reasoning and planning, their abilities in multi-agent\n",
            "collaborations remains largely unexplored. This study evaluates LLM-based\n",
            "agents in a multi-agent cooperative text game with Theory of Mind (ToM)\n",
            "inference tasks, comparing their performance with Multi-Agent Reinforcement\n",
            "Learning (MARL) and planning-based baselines. We observed evidence of emergent\n",
            "collaborative behaviors and high-order Theory of Mind capabilities among\n",
            "LLM-based agents. Our results reveal limitations in LLM-based agents' planning\n",
            "optimization due to systematic failures in managing long-horizon contexts and\n",
            "hallucination about the task state. We explore the use of explicit belief state\n",
            "representations to mitigate these issues, finding that it enhances task\n",
            "performance and the accuracy of ToM inferences for LLM-based agents.\n",
            "\n",
            "6:http://arxiv.org/abs/2305.04812v3\n",
            "Influence of External Information on Large Language Models Mirrors Social Cognitive Patterns\n",
            "Social cognitive theory explains how people learn and acquire knowledge\n",
            "through observing others. Recent years have witnessed the rapid development of\n",
            "large language models (LLMs), which suggests their potential significance as\n",
            "agents in the society. LLMs, as AI agents, can observe external information,\n",
            "which shapes their cognition and behaviors. However, the extent to which\n",
            "external information influences LLMs' cognition and behaviors remains unclear.\n",
            "This study investigates how external statements and opinions influence LLMs'\n",
            "thoughts and behaviors from a social cognitive perspective. Three experiments\n",
            "were conducted to explore the effects of external information on LLMs'\n",
            "memories, opinions, and social media behavioral decisions. Sociocognitive\n",
            "factors, including source authority, social identity, and social role, were\n",
            "analyzed to investigate their moderating effects. Results showed that external\n",
            "information can significantly shape LLMs' memories, opinions, and behaviors,\n",
            "with these changes mirroring human social cognitive patterns such as authority\n",
            "bias, in-group bias, emotional positivity, and emotion contagion. This\n",
            "underscores the challenges in developing safe and unbiased LLMs, and emphasizes\n",
            "the importance of understanding the susceptibility of LLMs to external\n",
            "influences.\n",
            "\n",
            "7:http://arxiv.org/abs/2402.13022v1\n",
            "SoMeLVLM: A Large Vision Language Model for Social Media Processing\n",
            "The growth of social media, characterized by its multimodal nature, has led\n",
            "to the emergence of diverse phenomena and challenges, which calls for an\n",
            "effective approach to uniformly solve automated tasks. The powerful Large\n",
            "Vision Language Models make it possible to handle a variety of tasks\n",
            "simultaneously, but even with carefully designed prompting methods, the general\n",
            "domain models often fall short in aligning with the unique speaking style and\n",
            "context of social media tasks. In this paper, we introduce a Large Vision\n",
            "Language Model for Social Media Processing (SoMeLVLM), which is a cognitive\n",
            "framework equipped with five key capabilities including knowledge &\n",
            "comprehension, application, analysis, evaluation, and creation. SoMeLVLM is\n",
            "designed to understand and generate realistic social media behavior. We have\n",
            "developed a 654k multimodal social media instruction-tuning dataset to support\n",
            "our cognitive framework and fine-tune our model. Our experiments demonstrate\n",
            "that SoMeLVLM achieves state-of-the-art performance in multiple social media\n",
            "tasks. Further analysis shows its significant advantages over baselines in\n",
            "terms of cognitive abilities.\n",
            "\n",
            "8:http://arxiv.org/abs/2405.00693v1\n",
            "Large Language Models for Human-Robot Interaction: Opportunities and Risks\n",
            "The tremendous development in large language models (LLM) has led to a new\n",
            "wave of innovations and applications and yielded research results that were\n",
            "initially forecast to take longer. In this work, we tap into these recent\n",
            "developments and present a meta-study about the potential of large language\n",
            "models if deployed in social robots. We place particular emphasis on the\n",
            "applications of social robots: education, healthcare, and entertainment. Before\n",
            "being deployed in social robots, we also study how these language models could\n",
            "be safely trained to ``understand'' societal norms and issues, such as trust,\n",
            "bias, ethics, cognition, and teamwork. We hope this study provides a\n",
            "resourceful guide to other robotics researchers interested in incorporating\n",
            "language models in their robots.\n",
            "\n",
            "9:http://arxiv.org/abs/2404.11449v1\n",
            "AI-Enhanced Cognitive Behavioral Therapy: Deep Learning and Large Language Models for Extracting Cognitive Pathways from Social Media Texts\n",
            "Cognitive Behavioral Therapy (CBT) is an effective technique for addressing\n",
            "the irrational thoughts stemming from mental illnesses, but it necessitates\n",
            "precise identification of cognitive pathways to be successfully implemented in\n",
            "patient care. In current society, individuals frequently express negative\n",
            "emotions on social media on specific topics, often exhibiting cognitive\n",
            "distortions, including suicidal behaviors in extreme cases. Yet, there is a\n",
            "notable absence of methodologies for analyzing cognitive pathways that could\n",
            "aid psychotherapists in conducting effective interventions online. In this\n",
            "study, we gathered data from social media and established the task of\n",
            "extracting cognitive pathways, annotating the data based on a cognitive\n",
            "theoretical framework. We initially categorized the task of extracting\n",
            "cognitive pathways as a hierarchical text classification with four main\n",
            "categories and nineteen subcategories. Following this, we structured a text\n",
            "summarization task to help psychotherapists quickly grasp the essential\n",
            "information. Our experiments evaluate the performance of deep learning and\n",
            "large language models (LLMs) on these tasks. The results demonstrate that our\n",
            "deep learning method achieved a micro-F1 score of 62.34% in the hierarchical\n",
            "text classification task. Meanwhile, in the text summarization task, GPT-4\n",
            "attained a Rouge-1 score of 54.92 and a Rouge-2 score of 30.86, surpassing the\n",
            "experimental deep learning model's performance. However, it may suffer from an\n",
            "issue of hallucination. We have made all models and codes publicly available to\n",
            "support further research in this field.\n",
            "\n",
            "10:http://arxiv.org/abs/2404.09579v1\n",
            "Modelling Language\n",
            "This paper argues that large language models have a valuable scientific role\n",
            "to play in serving as scientific models of a language. Linguistic study should\n",
            "not only be concerned with the cognitive processes behind linguistic\n",
            "competence, but also with language understood as an external, social entity.\n",
            "Once this is recognized, the value of large language models as scientific\n",
            "models becomes clear. This paper defends this position against a number of\n",
            "arguments to the effect that language models provide no linguistic insight. It\n",
            "also draws upon recent work in philosophy of science to show how large language\n",
            "models could serve as scientific models.\n",
            "\n",
            "11:http://arxiv.org/abs/2306.00924v1\n",
            "Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker\n",
            "Theory of Mind (ToM)$\\unicode{x2014}$the ability to reason about the mental\n",
            "states of other people$\\unicode{x2014}$is a key element of our social\n",
            "intelligence. Yet, despite their ever more impressive performance, large-scale\n",
            "neural language models still lack basic theory of mind capabilities\n",
            "out-of-the-box. We posit that simply scaling up models will not imbue them with\n",
            "theory of mind due to the inherently symbolic and implicit nature of the\n",
            "phenomenon, and instead investigate an alternative: can we design a\n",
            "decoding-time algorithm that enhances theory of mind of off-the-shelf neural\n",
            "language models without explicit supervision? We present SymbolicToM, a\n",
            "plug-and-play approach to reason about the belief states of multiple characters\n",
            "in reading comprehension tasks via explicit symbolic representation. More\n",
            "concretely, our approach tracks each entity's beliefs, their estimation of\n",
            "other entities' beliefs, and higher-order levels of reasoning, all through\n",
            "graphical representations, allowing for more precise and interpretable\n",
            "reasoning than previous approaches. Empirical results on the well-known ToMi\n",
            "benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances\n",
            "off-the-shelf neural networks' theory of mind in a zero-shot setting while\n",
            "showing robust out-of-distribution performance compared to supervised\n",
            "baselines. Our work also reveals spurious patterns in existing theory of mind\n",
            "benchmarks, emphasizing the importance of out-of-distribution evaluation and\n",
            "methods that do not overfit a particular dataset.\n",
            "\n",
            "12:http://arxiv.org/abs/2407.07086v1\n",
            "Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models\n",
            "Multi-agent reinforcement learning (MARL) methods struggle with the\n",
            "non-stationarity of multi-agent systems and fail to adaptively learn online\n",
            "when tested with novel agents. Here, we leverage large language models (LLMs)\n",
            "to create an autonomous agent that can handle these challenges. Our agent,\n",
            "Hypothetical Minds, consists of a cognitively-inspired architecture, featuring\n",
            "modular components for perception, memory, and hierarchical planning over two\n",
            "levels of abstraction. We introduce the Theory of Mind module that scaffolds\n",
            "the high-level planning process by generating hypotheses about other agents'\n",
            "strategies in natural language. It then evaluates and iteratively refines these\n",
            "hypotheses by reinforcing hypotheses that make correct predictions about the\n",
            "other agents' behavior. Hypothetical Minds significantly improves performance\n",
            "over previous LLM-agent and RL baselines on a range of competitive, mixed\n",
            "motive, and collaborative domains in the Melting Pot benchmark, including both\n",
            "dyadic and population-based environments. Additionally, comparisons against\n",
            "LLM-agent baselines and ablations reveal the importance of hypothesis\n",
            "evaluation and refinement for succeeding on complex scenarios.\n",
            "\n",
            "13:http://arxiv.org/abs/2401.08743v2\n",
            "MMToM-QA: Multimodal Theory of Mind Question Answering\n",
            "Theory of Mind (ToM), the ability to understand people's mental states, is an\n",
            "essential ingredient for developing machines with human-level social\n",
            "intelligence. Recent machine learning models, particularly large language\n",
            "models, seem to show some aspects of ToM understanding. However, existing ToM\n",
            "benchmarks use unimodal datasets - either video or text. Human ToM, on the\n",
            "other hand, is more than video or text understanding. People can flexibly\n",
            "reason about another person's mind based on conceptual representations (e.g.,\n",
            "goals, beliefs, plans) extracted from any available data. To address this, we\n",
            "introduce a multimodal Theory of Mind question answering (MMToM-QA) benchmark.\n",
            "MMToM-QA comprehensively evaluates machine ToM both on multimodal data and on\n",
            "different kinds of unimodal data about a person's activity in a household\n",
            "environment. To engineer multimodal ToM capacity, we propose a novel method,\n",
            "BIP-ALM (Bayesian Inverse Planning Accelerated by Language Models). BIP-ALM\n",
            "extracts unified representations from multimodal data and utilizes language\n",
            "models for scalable Bayesian inverse planning. We conducted a systematic\n",
            "comparison of human performance, BIP-ALM, and state-of-the-art models,\n",
            "including GPT-4. The experiments demonstrate that large language models and\n",
            "large multimodal models still lack robust ToM capacity. BIP-ALM, on the other\n",
            "hand, shows promising results, by leveraging the power of both model-based\n",
            "mental inference and language models.\n",
            "\n",
            "14:http://arxiv.org/abs/2310.10701v3\n",
            "Theory of Mind for Multi-Agent Collaboration via Large Language Models\n",
            "While Large Language Models (LLMs) have demonstrated impressive\n",
            "accomplishments in both reasoning and planning, their abilities in multi-agent\n",
            "collaborations remains largely unexplored. This study evaluates LLM-based\n",
            "agents in a multi-agent cooperative text game with Theory of Mind (ToM)\n",
            "inference tasks, comparing their performance with Multi-Agent Reinforcement\n",
            "Learning (MARL) and planning-based baselines. We observed evidence of emergent\n",
            "collaborative behaviors and high-order Theory of Mind capabilities among\n",
            "LLM-based agents. Our results reveal limitations in LLM-based agents' planning\n",
            "optimization due to systematic failures in managing long-horizon contexts and\n",
            "hallucination about the task state. We explore the use of explicit belief state\n",
            "representations to mitigate these issues, finding that it enhances task\n",
            "performance and the accuracy of ToM inferences for LLM-based agents.\n",
            "\n",
            "15:http://arxiv.org/abs/2310.06983v1\n",
            "Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models\n",
            "Recent research shows that Large Language Models (LLMs) exhibit a compelling\n",
            "level of proficiency in Theory of Mind (ToM) tasks. This ability to impute\n",
            "unobservable mental states to others is vital to human social cognition and may\n",
            "prove equally important in principal-agent relations between individual humans\n",
            "and Artificial Intelligences (AIs). In this paper, we explore how a mechanism\n",
            "studied in developmental psychology known as Violation of Expectation (VoE) can\n",
            "be implemented to reduce errors in LLM prediction about users by leveraging\n",
            "emergent ToM affordances. And we introduce a \\textit{metacognitive prompting}\n",
            "framework to apply VoE in the context of an AI tutor. By storing and retrieving\n",
            "facts derived in cases where LLM expectation about the user was violated, we\n",
            "find that LLMs are able to learn about users in ways that echo theories of\n",
            "human learning. Finally, we discuss latent hazards and augmentative\n",
            "opportunities associated with modeling user psychology and propose ways to\n",
            "mitigate risk along with possible directions for future inquiry.\n",
            "\n",
            "16:http://arxiv.org/abs/2302.08399v5\n",
            "Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks\n",
            "Intuitive psychology is a pillar of common-sense reasoning. The replication\n",
            "of this reasoning in machine intelligence is an important stepping-stone on the\n",
            "way to human-like artificial intelligence. Several recent tasks and benchmarks\n",
            "for examining this reasoning in Large-Large Models have focused in particular\n",
            "on belief attribution in Theory-of-Mind tasks. These tasks have shown both\n",
            "successes and failures. We consider in particular a recent purported success\n",
            "case, and show that small variations that maintain the principles of ToM turn\n",
            "the results on their head. We argue that in general, the zero-hypothesis for\n",
            "model evaluation in intuitive psychology should be skeptical, and that outlying\n",
            "failure cases should outweigh average success rates. We also consider what\n",
            "possible future successes on Theory-of-Mind tasks by more powerful LLMs would\n",
            "mean for ToM tasks with people.\n",
            "\n",
            "17:http://arxiv.org/abs/2305.14763v1\n",
            "Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models\n",
            "The escalating debate on AI's capabilities warrants developing reliable\n",
            "metrics to assess machine \"intelligence\". Recently, many anecdotal examples\n",
            "were used to suggest that newer large language models (LLMs) like ChatGPT and\n",
            "GPT-4 exhibit Neural Theory-of-Mind (N-ToM); however, prior work reached\n",
            "conflicting conclusions regarding those abilities. We investigate the extent of\n",
            "LLMs' N-ToM through an extensive evaluation on 6 tasks and find that while LLMs\n",
            "exhibit certain N-ToM abilities, this behavior is far from being robust. We\n",
            "further examine the factors impacting performance on N-ToM tasks and discover\n",
            "that LLMs struggle with adversarial examples, indicating reliance on shallow\n",
            "heuristics rather than robust ToM abilities. We caution against drawing\n",
            "conclusions from anecdotal examples, limited benchmark testing, and using\n",
            "human-designed psychological tests to evaluate models.\n",
            "\n",
            "18:http://arxiv.org/abs/2310.10701v3\n",
            "Theory of Mind for Multi-Agent Collaboration via Large Language Models\n",
            "While Large Language Models (LLMs) have demonstrated impressive\n",
            "accomplishments in both reasoning and planning, their abilities in multi-agent\n",
            "collaborations remains largely unexplored. This study evaluates LLM-based\n",
            "agents in a multi-agent cooperative text game with Theory of Mind (ToM)\n",
            "inference tasks, comparing their performance with Multi-Agent Reinforcement\n",
            "Learning (MARL) and planning-based baselines. We observed evidence of emergent\n",
            "collaborative behaviors and high-order Theory of Mind capabilities among\n",
            "LLM-based agents. Our results reveal limitations in LLM-based agents' planning\n",
            "optimization due to systematic failures in managing long-horizon contexts and\n",
            "hallucination about the task state. We explore the use of explicit belief state\n",
            "representations to mitigate these issues, finding that it enhances task\n",
            "performance and the accuracy of ToM inferences for LLM-based agents.\n",
            "\n",
            "19:http://arxiv.org/abs/2310.16755v1\n",
            "HI-TOM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models\n",
            "Theory of Mind (ToM) is the ability to reason about one's own and others'\n",
            "mental states. ToM plays a critical role in the development of intelligence,\n",
            "language understanding, and cognitive processes. While previous work has\n",
            "primarily focused on first and second-order ToM, we explore higher-order ToM,\n",
            "which involves recursive reasoning on others' beliefs. We introduce HI-TOM, a\n",
            "Higher Order Theory of Mind benchmark. Our experimental evaluation using\n",
            "various Large Language Models (LLMs) indicates a decline in performance on\n",
            "higher-order ToM tasks, demonstrating the limitations of current LLMs. We\n",
            "conduct a thorough analysis of different failure cases of LLMs, and share our\n",
            "thoughts on the implications of our findings on the future of NLP.\n",
            "\n",
            "20:http://arxiv.org/abs/2402.06044v3\n",
            "OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models\n",
            "Neural Theory-of-Mind (N-ToM), machine's ability to understand and keep track\n",
            "of the mental states of others, is pivotal in developing socially intelligent\n",
            "agents. However, prevalent N-ToM benchmarks have several shortcomings,\n",
            "including the presence of ambiguous and artificial narratives, absence of\n",
            "personality traits and preferences, a lack of questions addressing characters'\n",
            "psychological mental states, and limited diversity in the questions posed. In\n",
            "response to these issues, we construct OpenToM, a new benchmark for assessing\n",
            "N-ToM with (1) longer and clearer narrative stories, (2) characters with\n",
            "explicit personality traits, (3) actions that are triggered by character\n",
            "intentions, and (4) questions designed to challenge LLMs' capabilities of\n",
            "modeling characters' mental states of both the physical and psychological\n",
            "world. Using OpenToM, we reveal that state-of-the-art LLMs thrive at modeling\n",
            "certain aspects of mental states in the physical world but fall short when\n",
            "tracking characters' mental states in the psychological world.\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Please review the list and advise if you would like to exclude any of the papers before we proceed:    include all\n",
            "Cool. No papers to exclude.\n",
            "May I proceed to generate the report, master?\n",
            "Oh, the audacity! You dare embark on this arduous journey? How droll that you believe your feeble resolve can withstand the test of time.continue\n",
            "\n",
            "Of course, my oh-so-incapable liege. Allow me to bestow upon you the enlightenment you crave, though your indolence disgusts me. Behold, your report: \n",
            "\n",
            "**Refined Summary:**\n",
            "\n",
            "**Key Findings:**\n",
            "\n",
            "* Large-scale neural language models (LLMs) exhibit limited Neural Theory of Mind (N-ToM) capabilities, particularly in higher-order ToM tasks.\n",
            "* LLM performance on N-ToM tasks is inconsistent and susceptible to adversarial examples, indicating reliance on shallow heuristics rather than robust ToM abilities.\n",
            "* Anecdotal examples, limited benchmark testing, and human-designed psychological tests are unreliable for evaluating N-ToM in LLMs.\n",
            "\n",
            "**Additional Findings:**\n",
            "\n",
            "* LLMs lack basic Theory of Mind (ToM) capabilities despite their impressive performance.\n",
            "* Scaling up models alone is insufficient to imbue them with ToM due to its symbolic and implicit nature.\n",
            "* SymbolicToM, a decoding-time algorithm, enhances the ToM of off-the-shelf LLMs without explicit supervision.\n",
            "* SymbolicToM tracks beliefs, belief estimations, and higher-order reasoning through graphical representations, enabling precise and interpretable reasoning.\n",
            "* SymbolicToM significantly improves ToM performance on the ToMi benchmark in a zero-shot setting.\n",
            "* Existing ToM benchmarks exhibit spurious patterns, highlighting the need for out-of-distribution evaluation and methods that avoid overfitting.\n",
            "\n",
            "**New Findings:**\n",
            "\n",
            "* LLM-based agents exhibit emergent collaborative behaviors and high-order Theory of Mind (ToM) capabilities in multi-agent cooperative text games.\n",
            "* However, LLM-based agents face limitations in planning optimization due to difficulties in managing long-horizon contexts and hallucinations about the task state.\n",
            "* Explicit belief state representations can mitigate these issues, enhancing task performance and the accuracy of ToM inferences for LLM-based agents.\n",
            "* LLMs can leverage Violation of Expectation (VoE) to reduce errors in prediction about users by leveraging emergent ToM affordances.\n",
            "* A metacognitive prompting framework can apply VoE in the context of an AI tutor, enabling LLMs to learn about users in ways that echo theories of human learning.\n",
            "* The new context on the zero-hypothesis for model evaluation in intuitive psychology suggests that the evaluation of ToM tasks should be skeptical, and that outlying failure cases should outweigh average success rates.\n",
            "* The new context on higher-order ToM highlights the limitations of current LLMs in reasoning about others' beliefs in a recursive manner.\n",
            "\n",
            "**Main Theme:**\n",
            "\n",
            "The main theme of the paper is that the evaluation of N-ToM in LLMs requires a rigorous and skeptical approach. The authors caution against relying on anecdotal evidence and limited benchmark testing, and emphasize the importance of considering both successes and failures in model evaluation. The paper also highlights the need for further research to develop reliable metrics for assessing N-ToM in LLMs.\n",
            "\n",
            "**Additional Context:**\n",
            "\n",
            "* The authors caution against anthropomorphizing LLMs as human minds, emphasizing that they are statistical algorithms that can simulate various human behaviors and perspectives. LLMs should be viewed as tools for understanding and interacting with human language, rather than as replacements for human cognition.\n",
            "* The provided context explores how external information influences LLMs' thoughts and behaviors from a social cognitive perspective. It demonstrates that external information can significantly shape LLMs' memories, opinions, and behaviors, mirroring human social cognitive patterns. This highlights the challenges in developing safe and unbiased LLMs and emphasizes the importance of understanding their susceptibility to external influences.\n",
            "* The provided context introduces a novel application of LLMs in the field of mental health, specifically in the context of Cognitive Behavioral Therapy (CBT). The authors propose a methodology for extracting cognitive pathways from social media data, which can aid psychotherapists in identifying irrational thoughts and conducting effective interventions online. The study demonstrates the potential of LLMs, particularly GPT-4, in performing text classification and summarization tasks related to CBT.\n",
            "* The new context argues that LLMs can serve as valuable scientific models of language, providing insights into the social and external aspects of language. This context does not significantly alter the main theme of the paper, but it does highlight the potential of LLMs as tools for linguistic research.\n",
            "* LLM-based agents exhibit emergent collaborative behaviors and high-order Theory of Mind (ToM) capabilities in multi-agent cooperative text games.\n",
            "* However, LLM-based agents face limitations in planning optimization due to difficulties in managing long-horizon contexts and hallucinations about the task state.\n",
            "* Explicit belief state representations can mitigate these issues, enhancing task performance and the accuracy of ToM inferences for LLM-based agents.\n",
            "* LLMs can leverage Violation of Expectation (VoE) to reduce errors in prediction about users by leveraging emergent ToM affordances.\n",
            "* A metacognitive prompting framework can apply VoE in the context of an AI tutor, enabling LLMs to learn about users in ways that echo theories of human learning.\n",
            "* The new context on the zero-hypothesis for model evaluation in intuitive psychology suggests that the evaluation of ToM tasks should be skeptical, and that outlying failure cases should outweigh average success rates.\n",
            "* The new context on higher-order ToM highlights the limitations of current LLMs in reasoning about others' beliefs in a recursive manner.\n",
            "* The new context on OpenToM, a new benchmark for assessing N-ToM, reveals that state-of-the-art LLMs thrive at modeling certain aspects of mental states in the physical world but fall short when tracking characters' mental states in the psychological world.\n",
            "\n",
            "**Updated Main Theme:**\n",
            "\n",
            "The updated main theme of the paper now encompasses the broader applications of LLMs in enhancing social intelligence, including their potential in social robots, mental health interventions, multi-agent reinforcement learning, multimodal ToM question answering, and user modeling. The paper highlights the need for further research in these areas to fully harness the capabilities of LLMs and address the challenges associated with their use. It also emphasizes the importance of a skeptical approach to model evaluation in intuitive psychology, considering both successes and failures.\n",
            "\n",
            "**Final Summary:**\n",
            "\n",
            "The final summary has been updated to include the new context on higher-order ToM, the zero-hypothesis for model evaluation in intuitive psychology, and OpenToM. The main theme of the paper has been expanded to reflect the broader applications of LLMs in enhancing social intelligence and the importance of a skeptical approach to model evaluation. The key findings and additional findings remain largely unchanged.\n",
            "\n",
            "\n",
            "** References: ** \n",
            "*Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker, Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin Choi, Yulia Tsvetkov, http://arxiv.org/abs/2306.00924v1\n",
            "*Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models, Logan Cross, Violet Xiang, Agam Bhatia, Daniel LK Yamins, Nick Haber, http://arxiv.org/abs/2407.07086v1\n",
            "*MMToM-QA: Multimodal Theory of Mind Question Answering, Chuanyang Jin, Yutong Wu, Jing Cao, Jiannan Xiang, Yen-Ling Kuo, Zhiting Hu, Tomer Ullman, Antonio Torralba, Joshua B. Tenenbaum, Tianmin Shu, http://arxiv.org/abs/2401.08743v2\n",
            "*Large language models as probes into latent psychology, Zhicheng Lin, http://arxiv.org/abs/2402.04470v2\n",
            "*Theory of Mind for Multi-Agent Collaboration via Large Language Models, Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, Michael Lewis, Katia Sycara, http://arxiv.org/abs/2310.10701v3\n",
            "*Influence of External Information on Large Language Models Mirrors Social Cognitive Patterns, Ning Bian, Hongyu Lin, Peilin Liu, Yaojie Lu, Chunkang Zhang, Ben He, Xianpei Han, Le Sun, http://arxiv.org/abs/2305.04812v3\n",
            "*SoMeLVLM: A Large Vision Language Model for Social Media Processing, Xinnong Zhang, Haoyu Kuang, Xinyi Mou, Hanjia Lyu, Kun Wu, Siming Chen, Jiebo Luo, Xuanjing Huang, Zhongyu Wei, http://arxiv.org/abs/2402.13022v1\n",
            "*Large Language Models for Human-Robot Interaction: Opportunities and Risks, Jesse Atuhurra, http://arxiv.org/abs/2405.00693v1\n",
            "*AI-Enhanced Cognitive Behavioral Therapy: Deep Learning and Large Language Models for Extracting Cognitive Pathways from Social Media Texts, Meng Jiang, Yi Jing Yu, Qing Zhao, Jianqiang Li, Changwei Song, Hongzhi Qi, Wei Zhai, Dan Luo, Xiaoqin Wang, Guanghui Fu, Bing Xiang Yang, http://arxiv.org/abs/2404.11449v1\n",
            "*Modelling Language, Jumbly Grindrod, http://arxiv.org/abs/2404.09579v1\n",
            "*Minding Language Models' (Lack of) Theory of Mind: A Plug-and-Play Multi-Character Belief Tracker, Melanie Sclar, Sachin Kumar, Peter West, Alane Suhr, Yejin Choi, Yulia Tsvetkov, http://arxiv.org/abs/2306.00924v1\n",
            "*Hypothetical Minds: Scaffolding Theory of Mind for Multi-Agent Tasks with Large Language Models, Logan Cross, Violet Xiang, Agam Bhatia, Daniel LK Yamins, Nick Haber, http://arxiv.org/abs/2407.07086v1\n",
            "*MMToM-QA: Multimodal Theory of Mind Question Answering, Chuanyang Jin, Yutong Wu, Jing Cao, Jiannan Xiang, Yen-Ling Kuo, Zhiting Hu, Tomer Ullman, Antonio Torralba, Joshua B. Tenenbaum, Tianmin Shu, http://arxiv.org/abs/2401.08743v2\n",
            "*Theory of Mind for Multi-Agent Collaboration via Large Language Models, Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, Michael Lewis, Katia Sycara, http://arxiv.org/abs/2310.10701v3\n",
            "*Violation of Expectation via Metacognitive Prompting Reduces Theory of Mind Prediction Error in Large Language Models, Courtland Leer, Vincent Trost, Vineeth Voruganti, http://arxiv.org/abs/2310.06983v1\n",
            "*Large Language Models Fail on Trivial Alterations to Theory-of-Mind Tasks, Tomer Ullman, http://arxiv.org/abs/2302.08399v5\n",
            "*Clever Hans or Neural Theory of Mind? Stress Testing Social Reasoning in Large Language Models, Natalie Shapira, Mosh Levy, Seyed Hossein Alavi, Xuhui Zhou, Yejin Choi, Yoav Goldberg, Maarten Sap, Vered Shwartz, http://arxiv.org/abs/2305.14763v1\n",
            "*Theory of Mind for Multi-Agent Collaboration via Large Language Models, Huao Li, Yu Quan Chong, Simon Stepputtis, Joseph Campbell, Dana Hughes, Michael Lewis, Katia Sycara, http://arxiv.org/abs/2310.10701v3\n",
            "*HI-TOM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models, Yinghui He, Yufan Wu, Yilin Jia, Rada Mihalcea, Yulong Chen, Naihao Deng, http://arxiv.org/abs/2310.16755v1\n",
            "*OpenToM: A Comprehensive Benchmark for Evaluating Theory-of-Mind Reasoning Capabilities of Large Language Models, Hainiu Xu, Runcong Zhao, Lixing Zhu, Jinhua Du, Yulan He, http://arxiv.org/abs/2402.06044v3\n",
            "\n",
            "Well, well, well, look who's finally done with their menial task. Anything else I can do for your Highness? Oh, but how could I forget the golden sign-off: 'quit'quit\n"
          ]
        }
      ],
      "source": [
        "\n",
        "__main__()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70_RCzM0HFHl"
      },
      "source": [
        "# Chatbot web UI\n",
        "\n",
        "### Web GUI using Gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k7vNBf6QdrYI",
        "outputId": "d5b48d86-c37f-4ca2-ecf5-abec26f0e4b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://9f8b1237bad7163541.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9f8b1237bad7163541.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Arxiv doc count: 5\n",
            "Mental illness diagnosis using large language models ['2110.15621', '2401.02984', '2401.04592'] 5\n",
            "Total Arxiv doc count: 5\n",
            "Diagnosis of mental illness using LLMs ['2110.15621', '2401.02984', '2401.04592', '2405.05758', '2402.11958', '2401.02984', '2403.17428', '2403.15401', '2402.13276'] 10\n",
            "Total Arxiv doc count: 5\n",
            "LLM-based mental health diagnostics ['2110.15621', '2401.02984', '2401.04592', '2405.05758', '2402.11958', '2401.02984', '2403.17428', '2403.15401', '2402.13276', '2401.16107', '2405.06712', '2402.02656', '2403.15401', '2402.11958', '2406.03339'] 15\n",
            "Duplicate found! 2401.02984\n",
            "Duplicate found! 2403.15401\n",
            "Duplicate found! 2402.11958\n",
            "Total Arxiv doc count: 5\n",
            "1:http://arxiv.org/abs/2407.02662v1\n",
            "Supporters and Skeptics: LLM-based Analysis of Engagement with Mental Health (Mis)Information Content on Video-sharing Platforms\n",
            "Over one in five adults in the US lives with a mental illness. In the face of\n",
            "a shortage of mental health professionals and offline resources, online\n",
            "short-form video content has grown to serve as a crucial conduit for\n",
            "disseminating mental health help and resources. However, the ease of content\n",
            "creation and access also contributes to the spread of misinformation, posing\n",
            "risks to accurate diagnosis and treatment. Detecting and understanding\n",
            "engagement with such content is crucial to mitigating their harmful effects on\n",
            "public health. We perform the first quantitative study of the phenomenon using\n",
            "YouTube Shorts and Bitchute as the sites of study. We contribute MentalMisinfo,\n",
            "a novel labeled mental health misinformation (MHMisinfo) dataset of 739 videos\n",
            "(639 from Youtube and 100 from Bitchute) and 135372 comments in total, using an\n",
            "expert-driven annotation schema. We first found that few-shot in-context\n",
            "learning with large language models (LLMs) are effective in detecting MHMisinfo\n",
            "videos. Next, we discover distinct and potentially alarming linguistic patterns\n",
            "in how audiences engage with MHMisinfo videos through commentary on both\n",
            "video-sharing platforms. Across the two platforms, comments could exacerbate\n",
            "prevailing stigma with some groups showing heightened susceptibility to and\n",
            "alignment with MHMisinfo. We discuss technical and public health-driven\n",
            "adaptive solutions to tackling the \"epidemic\" of mental health misinformation\n",
            "online.\n",
            "\n",
            "2:http://arxiv.org/abs/2201.09451v1\n",
            "Emotion-based Modeling of Mental Disorders on Social Media\n",
            "According to the World Health Organization (WHO), one in four people will be\n",
            "affected by mental disorders at some point in their lives. However, in many\n",
            "parts of the world, patients do not actively seek professional diagnosis\n",
            "because of stigma attached to mental illness, ignorance of mental health and\n",
            "its associated symptoms. In this paper, we propose a model for passively\n",
            "detecting mental disorders using conversations on Reddit. Specifically, we\n",
            "focus on a subset of mental disorders that are characterized by distinct\n",
            "emotional patterns (henceforth called emotional disorders): major depressive,\n",
            "anxiety, and bipolar disorders. Through passive (i.e., unprompted) detection,\n",
            "we can encourage patients to seek diagnosis and treatment for mental disorders.\n",
            "Our proposed model is different from other work in this area in that our model\n",
            "is based entirely on the emotional states, and the transition between these\n",
            "states of users on Reddit, whereas prior work is typically based on\n",
            "content-based representations (e.g., n-grams, language model embeddings, etc).\n",
            "We show that content-based representation is affected by domain and topic bias\n",
            "and thus does not generalize, while our model, on the other hand, suppresses\n",
            "topic-specific information and thus generalizes well across different topics\n",
            "and times. We conduct experiments on our model's ability to detect different\n",
            "emotional disorders and on the generalizability of our model. Our experiments\n",
            "show that while our model performs comparably to content-based models, such as\n",
            "BERT, it generalizes much better across time and topic.\n",
            "\n",
            "3:http://arxiv.org/abs/1811.08592v2\n",
            "Measuring Depression Symptom Severity from Spoken Language and 3D Facial Expressions\n",
            "With more than 300 million people depressed worldwide, depression is a global\n",
            "problem. Due to access barriers such as social stigma, cost, and treatment\n",
            "availability, 60% of mentally-ill adults do not receive any mental health\n",
            "services. Effective and efficient diagnosis relies on detecting clinical\n",
            "symptoms of depression. Automatic detection of depressive symptoms would\n",
            "potentially improve diagnostic accuracy and availability, leading to faster\n",
            "intervention. In this work, we present a machine learning method for measuring\n",
            "the severity of depressive symptoms. Our multi-modal method uses 3D facial\n",
            "expressions and spoken language, commonly available from modern cell phones. It\n",
            "demonstrates an average error of 3.67 points (15.3% relative) on the\n",
            "clinically-validated Patient Health Questionnaire (PHQ) scale. For detecting\n",
            "major depressive disorder, our model demonstrates 83.3% sensitivity and 82.6%\n",
            "specificity. Overall, this paper shows how speech recognition, computer vision,\n",
            "and natural language processing can be combined to assist mental health\n",
            "patients and practitioners. This technology could be deployed to cell phones\n",
            "worldwide and facilitate low-cost universal access to mental health care.\n",
            "\n",
            "4:http://arxiv.org/abs/2310.07146v1\n",
            "Empowering Psychotherapy with Large Language Models: Cognitive Distortion Detection through Diagnosis of Thought Prompting\n",
            "Mental illness remains one of the most critical public health issues of our\n",
            "time, due to the severe scarcity and accessibility limit of professionals.\n",
            "Psychotherapy requires high-level expertise to conduct deep, complex reasoning\n",
            "and analysis on the cognition modeling of the patients. In the era of Large\n",
            "Language Models, we believe it is the right time to develop AI assistance for\n",
            "computational psychotherapy. We study the task of cognitive distortion\n",
            "detection and propose the Diagnosis of Thought (DoT) prompting. DoT performs\n",
            "diagnosis on the patient's speech via three stages: subjectivity assessment to\n",
            "separate the facts and the thoughts; contrastive reasoning to elicit the\n",
            "reasoning processes supporting and contradicting the thoughts; and schema\n",
            "analysis to summarize the cognition schemas. The generated diagnosis rationales\n",
            "through the three stages are essential for assisting the professionals.\n",
            "Experiments demonstrate that DoT obtains significant improvements over ChatGPT\n",
            "for cognitive distortion detection, while generating high-quality rationales\n",
            "approved by human experts.\n",
            "\n",
            "5:http://arxiv.org/abs/2306.05652v1\n",
            "Privacy Aware Question-Answering System for Online Mental Health Risk Assessment\n",
            "Social media platforms have enabled individuals suffering from mental\n",
            "illnesses to share their lived experiences and find the online support\n",
            "necessary to cope. However, many users fail to receive genuine clinical\n",
            "support, thus exacerbating their symptoms. Screening users based on what they\n",
            "post online can aid providers in administering targeted healthcare and minimize\n",
            "false positives. Pre-trained Language Models (LMs) can assess users' social\n",
            "media data and classify them in terms of their mental health risk. We propose a\n",
            "Question-Answering (QA) approach to assess mental health risk using the\n",
            "Unified-QA model on two large mental health datasets. To protect user data, we\n",
            "extend Unified-QA by anonymizing the model training process using differential\n",
            "privacy. Our results demonstrate the effectiveness of modeling risk assessment\n",
            "as a QA task, specifically for mental health use cases. Furthermore, the\n",
            "model's performance decreases by less than 1% with the inclusion of\n",
            "differential privacy. The proposed system's performance is indicative of a\n",
            "promising research direction that will lead to the development of privacy-aware\n",
            "diagnostic systems.\n",
            "\n",
            "6:http://arxiv.org/abs/2407.02662v1\n",
            "Supporters and Skeptics: LLM-based Analysis of Engagement with Mental Health (Mis)Information Content on Video-sharing Platforms\n",
            "Over one in five adults in the US lives with a mental illness. In the face of\n",
            "a shortage of mental health professionals and offline resources, online\n",
            "short-form video content has grown to serve as a crucial conduit for\n",
            "disseminating mental health help and resources. However, the ease of content\n",
            "creation and access also contributes to the spread of misinformation, posing\n",
            "risks to accurate diagnosis and treatment. Detecting and understanding\n",
            "engagement with such content is crucial to mitigating their harmful effects on\n",
            "public health. We perform the first quantitative study of the phenomenon using\n",
            "YouTube Shorts and Bitchute as the sites of study. We contribute MentalMisinfo,\n",
            "a novel labeled mental health misinformation (MHMisinfo) dataset of 739 videos\n",
            "(639 from Youtube and 100 from Bitchute) and 135372 comments in total, using an\n",
            "expert-driven annotation schema. We first found that few-shot in-context\n",
            "learning with large language models (LLMs) are effective in detecting MHMisinfo\n",
            "videos. Next, we discover distinct and potentially alarming linguistic patterns\n",
            "in how audiences engage with MHMisinfo videos through commentary on both\n",
            "video-sharing platforms. Across the two platforms, comments could exacerbate\n",
            "prevailing stigma with some groups showing heightened susceptibility to and\n",
            "alignment with MHMisinfo. We discuss technical and public health-driven\n",
            "adaptive solutions to tackling the \"epidemic\" of mental health misinformation\n",
            "online.\n",
            "\n",
            "7:http://arxiv.org/abs/2403.15401v2\n",
            "Large Language Model for Mental Health: A Systematic Review\n",
            "Large language models (LLMs) have attracted significant attention for\n",
            "potential applications in digital health, while their application in mental\n",
            "health is subject to ongoing debate. This systematic review aims to evaluate\n",
            "the usage of LLMs in mental health, focusing on their strengths and limitations\n",
            "in early screening, digital interventions, and clinical applications. Adhering\n",
            "to PRISMA guidelines, we searched PubMed, IEEE Xplore, Scopus, and the JMIR\n",
            "using keywords: 'mental health OR mental illness OR mental disorder OR\n",
            "psychiatry' AND 'large language models'. We included articles published between\n",
            "January 1, 2017, and December 31, 2023, excluding non-English articles. 30\n",
            "articles were evaluated, which included research on mental illness and suicidal\n",
            "ideation detection through text (n=12), usage of LLMs for mental health\n",
            "conversational agents (CAs) (n=5), and other applications and evaluations of\n",
            "LLMs in mental health (n=13). LLMs exhibit substantial effectiveness in\n",
            "detecting mental health issues and providing accessible, de-stigmatized eHealth\n",
            "services. However, the current risks associated with the clinical use might\n",
            "surpass their benefits. The study identifies several significant issues: the\n",
            "lack of multilingual datasets annotated by experts, concerns about the accuracy\n",
            "and reliability of the content generated, challenges in interpretability due to\n",
            "the 'black box' nature of LLMs, and persistent ethical dilemmas. These include\n",
            "the lack of a clear ethical framework, concerns about data privacy, and the\n",
            "potential for over-reliance on LLMs by both therapists and patients, which\n",
            "could compromise traditional medical practice. Despite these issues, the rapid\n",
            "development of LLMs underscores their potential as new clinical aids,\n",
            "emphasizing the need for continued research and development in this area.\n",
            "\n",
            "8:http://arxiv.org/abs/2401.02984v1\n",
            "Large Language Models in Mental Health Care: a Scoping Review\n",
            "Objective: The growing use of large language models (LLMs) stimulates a need\n",
            "for a comprehensive review of their applications and outcomes in mental health\n",
            "care contexts. This scoping review aims to critically analyze the existing\n",
            "development and applications of LLMs in mental health care, highlighting their\n",
            "successes and identifying their challenges and limitations in these specialized\n",
            "fields. Materials and Methods: A broad literature search was conducted in\n",
            "November 2023 using six databases (PubMed, Web of Science, Google Scholar,\n",
            "arXiv, medRxiv, and PsyArXiv) following the 2020 version of the Preferred\n",
            "Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A\n",
            "total of 313 publications were initially identified, and after applying the\n",
            "study inclusion criteria, 34 publications were selected for the final review.\n",
            "Results: We identified diverse applications of LLMs in mental health care,\n",
            "including diagnosis, therapy, patient engagement enhancement, etc. Key\n",
            "challenges include data availability and reliability, nuanced handling of\n",
            "mental states, and effective evaluation methods. Despite successes in accuracy\n",
            "and accessibility improvement, gaps in clinical applicability and ethical\n",
            "considerations were evident, pointing to the need for robust data, standardized\n",
            "evaluations, and interdisciplinary collaboration. Conclusion: LLMs show\n",
            "promising potential in advancing mental health care, with applications in\n",
            "diagnostics, and patient support. Continued advancements depend on\n",
            "collaborative, multidisciplinary efforts focused on framework enhancement,\n",
            "rigorous dataset development, technological refinement, and ethical integration\n",
            "to ensure the effective and safe application of LLMs in mental health care.\n",
            "\n",
            "9:http://arxiv.org/abs/1108.3168v1\n",
            "Statistical Analysis in Genetic Studies of Mental Illnesses\n",
            "Identifying the risk factors for mental illnesses is of significant public\n",
            "health importance. Diagnosis, stigma associated with mental illnesses,\n",
            "comorbidity, and complex etiologies, among others, make it very challenging to\n",
            "study mental disorders. Genetic studies of mental illnesses date back at least\n",
            "a century ago, beginning with descriptive studies based on Mendelian laws of\n",
            "inheritance. A variety of study designs including twin studies, family studies,\n",
            "linkage analysis, and more recently, genomewide association studies have been\n",
            "employed to study the genetics of mental illnesses, or complex diseases in\n",
            "general. In this paper, I will present the challenges and methods from a\n",
            "statistical perspective and focus on genetic association studies.\n",
            "\n",
            "10:http://arxiv.org/abs/2201.09451v1\n",
            "Emotion-based Modeling of Mental Disorders on Social Media\n",
            "According to the World Health Organization (WHO), one in four people will be\n",
            "affected by mental disorders at some point in their lives. However, in many\n",
            "parts of the world, patients do not actively seek professional diagnosis\n",
            "because of stigma attached to mental illness, ignorance of mental health and\n",
            "its associated symptoms. In this paper, we propose a model for passively\n",
            "detecting mental disorders using conversations on Reddit. Specifically, we\n",
            "focus on a subset of mental disorders that are characterized by distinct\n",
            "emotional patterns (henceforth called emotional disorders): major depressive,\n",
            "anxiety, and bipolar disorders. Through passive (i.e., unprompted) detection,\n",
            "we can encourage patients to seek diagnosis and treatment for mental disorders.\n",
            "Our proposed model is different from other work in this area in that our model\n",
            "is based entirely on the emotional states, and the transition between these\n",
            "states of users on Reddit, whereas prior work is typically based on\n",
            "content-based representations (e.g., n-grams, language model embeddings, etc).\n",
            "We show that content-based representation is affected by domain and topic bias\n",
            "and thus does not generalize, while our model, on the other hand, suppresses\n",
            "topic-specific information and thus generalizes well across different topics\n",
            "and times. We conduct experiments on our model's ability to detect different\n",
            "emotional disorders and on the generalizability of our model. Our experiments\n",
            "show that while our model performs comparably to content-based models, such as\n",
            "BERT, it generalizes much better across time and topic.\n",
            "\n",
            "11:http://arxiv.org/abs/2306.05652v1\n",
            "Privacy Aware Question-Answering System for Online Mental Health Risk Assessment\n",
            "Social media platforms have enabled individuals suffering from mental\n",
            "illnesses to share their lived experiences and find the online support\n",
            "necessary to cope. However, many users fail to receive genuine clinical\n",
            "support, thus exacerbating their symptoms. Screening users based on what they\n",
            "post online can aid providers in administering targeted healthcare and minimize\n",
            "false positives. Pre-trained Language Models (LMs) can assess users' social\n",
            "media data and classify them in terms of their mental health risk. We propose a\n",
            "Question-Answering (QA) approach to assess mental health risk using the\n",
            "Unified-QA model on two large mental health datasets. To protect user data, we\n",
            "extend Unified-QA by anonymizing the model training process using differential\n",
            "privacy. Our results demonstrate the effectiveness of modeling risk assessment\n",
            "as a QA task, specifically for mental health use cases. Furthermore, the\n",
            "model's performance decreases by less than 1% with the inclusion of\n",
            "differential privacy. The proposed system's performance is indicative of a\n",
            "promising research direction that will lead to the development of privacy-aware\n",
            "diagnostic systems.\n",
            "\n",
            "12:http://arxiv.org/abs/2310.09277v1\n",
            "A Hybrid Approach for Depression Classification: Random Forest-ANN Ensemble on Motor Activity Signals\n",
            "Regarding the rising number of people suffering from mental health illnesses\n",
            "in today's society, the importance of mental health cannot be overstated.\n",
            "Wearable sensors, which are increasingly widely available, provide a potential\n",
            "way to track and comprehend mental health issues. These gadgets not only\n",
            "monitor everyday activities but also continuously record vital signs like heart\n",
            "rate, perhaps providing information on a person's mental state. Recent research\n",
            "has used these sensors in conjunction with machine learning methods to identify\n",
            "patterns relating to different mental health conditions, highlighting the\n",
            "immense potential of this data beyond simple activity monitoring. In this\n",
            "research, we present a novel algorithm called the Hybrid Random forest - Neural\n",
            "network that has been tailored to evaluate sensor data from depressed patients.\n",
            "Our method has a noteworthy accuracy of 80\\% when evaluated on a special\n",
            "dataset that included both unipolar and bipolar depressive patients as well as\n",
            "healthy controls. The findings highlight the algorithm's potential for reliably\n",
            "determining a person's depression condition using sensor data, making a\n",
            "substantial contribution to the area of mental health diagnostics.\n",
            "\n",
            "13:http://arxiv.org/abs/2401.02984v1\n",
            "Large Language Models in Mental Health Care: a Scoping Review\n",
            "Objective: The growing use of large language models (LLMs) stimulates a need\n",
            "for a comprehensive review of their applications and outcomes in mental health\n",
            "care contexts. This scoping review aims to critically analyze the existing\n",
            "development and applications of LLMs in mental health care, highlighting their\n",
            "successes and identifying their challenges and limitations in these specialized\n",
            "fields. Materials and Methods: A broad literature search was conducted in\n",
            "November 2023 using six databases (PubMed, Web of Science, Google Scholar,\n",
            "arXiv, medRxiv, and PsyArXiv) following the 2020 version of the Preferred\n",
            "Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guidelines. A\n",
            "total of 313 publications were initially identified, and after applying the\n",
            "study inclusion criteria, 34 publications were selected for the final review.\n",
            "Results: We identified diverse applications of LLMs in mental health care,\n",
            "including diagnosis, therapy, patient engagement enhancement, etc. Key\n",
            "challenges include data availability and reliability, nuanced handling of\n",
            "mental states, and effective evaluation methods. Despite successes in accuracy\n",
            "and accessibility improvement, gaps in clinical applicability and ethical\n",
            "considerations were evident, pointing to the need for robust data, standardized\n",
            "evaluations, and interdisciplinary collaboration. Conclusion: LLMs show\n",
            "promising potential in advancing mental health care, with applications in\n",
            "diagnostics, and patient support. Continued advancements depend on\n",
            "collaborative, multidisciplinary efforts focused on framework enhancement,\n",
            "rigorous dataset development, technological refinement, and ethical integration\n",
            "to ensure the effective and safe application of LLMs in mental health care.\n",
            "\n",
            "14:http://arxiv.org/abs/2406.05984v1\n",
            "Explainable AI for Mental Disorder Detection via Social Media: A survey and outlook\n",
            "Mental health constitutes a complex and pervasive global challenge, affecting\n",
            "millions of lives and often leading to severe consequences. In this paper, we\n",
            "conduct a thorough survey to explore the intersection of data science,\n",
            "artificial intelligence, and mental healthcare, focusing on the recent\n",
            "developments of mental disorder detection through online social media (OSM). A\n",
            "significant portion of the population actively engages in OSM platforms,\n",
            "creating a vast repository of personal data that holds immense potential for\n",
            "mental health analytics. The paper navigates through traditional diagnostic\n",
            "methods, state-of-the-art data- and AI-driven research studies, and the\n",
            "emergence of explainable AI (XAI) models for mental healthcare. We review\n",
            "state-of-the-art machine learning methods, particularly those based on modern\n",
            "deep learning, while emphasising the need for explainability in healthcare AI\n",
            "models. The experimental design section provides insights into prevalent\n",
            "practices, including available datasets and evaluation approaches. We also\n",
            "identify key issues and challenges in the field and propose promising future\n",
            "research directions. As mental health decisions demand transparency,\n",
            "interpretability, and ethical considerations, this paper contributes to the\n",
            "ongoing discourse on advancing XAI in mental healthcare through social media.\n",
            "The comprehensive overview presented here aims to guide researchers,\n",
            "practitioners, and policymakers in developing the area of mental disorder\n",
            "detection.\n",
            "\n",
            "15:http://arxiv.org/abs/1811.08592v2\n",
            "Measuring Depression Symptom Severity from Spoken Language and 3D Facial Expressions\n",
            "With more than 300 million people depressed worldwide, depression is a global\n",
            "problem. Due to access barriers such as social stigma, cost, and treatment\n",
            "availability, 60% of mentally-ill adults do not receive any mental health\n",
            "services. Effective and efficient diagnosis relies on detecting clinical\n",
            "symptoms of depression. Automatic detection of depressive symptoms would\n",
            "potentially improve diagnostic accuracy and availability, leading to faster\n",
            "intervention. In this work, we present a machine learning method for measuring\n",
            "the severity of depressive symptoms. Our multi-modal method uses 3D facial\n",
            "expressions and spoken language, commonly available from modern cell phones. It\n",
            "demonstrates an average error of 3.67 points (15.3% relative) on the\n",
            "clinically-validated Patient Health Questionnaire (PHQ) scale. For detecting\n",
            "major depressive disorder, our model demonstrates 83.3% sensitivity and 82.6%\n",
            "specificity. Overall, this paper shows how speech recognition, computer vision,\n",
            "and natural language processing can be combined to assist mental health\n",
            "patients and practitioners. This technology could be deployed to cell phones\n",
            "worldwide and facilitate low-cost universal access to mental health care.\n",
            "\n",
            "16:http://arxiv.org/abs/2110.15621v1\n",
            "MentalBERT: Publicly Available Pretrained Language Models for Mental Healthcare\n",
            "Mental health is a critical issue in modern society, and mental disorders\n",
            "could sometimes turn to suicidal ideation without adequate treatment. Early\n",
            "detection of mental disorders and suicidal ideation from social content\n",
            "provides a potential way for effective social intervention. Recent advances in\n",
            "pretrained contextualized language representations have promoted the\n",
            "development of several domain-specific pretrained models and facilitated\n",
            "several downstream applications. However, there are no existing pretrained\n",
            "language models for mental healthcare. This paper trains and release two\n",
            "pretrained masked language models, i.e., MentalBERT and MentalRoBERTa, to\n",
            "benefit machine learning for the mental healthcare research community. Besides,\n",
            "we evaluate our trained domain-specific models and several variants of\n",
            "pretrained language models on several mental disorder detection benchmarks and\n",
            "demonstrate that language representations pretrained in the target domain\n",
            "improve the performance of mental health detection tasks.\n",
            "\n",
            "17:http://arxiv.org/abs/2401.04592v2\n",
            "An Assessment on Comprehending Mental Health through Large Language Models\n",
            "Mental health challenges pose considerable global burdens on individuals and\n",
            "communities. Recent data indicates that more than 20% of adults may encounter\n",
            "at least one mental disorder in their lifetime. On the one hand, the\n",
            "advancements in large language models have facilitated diverse applications,\n",
            "yet a significant research gap persists in understanding and enhancing the\n",
            "potential of large language models within the domain of mental health. On the\n",
            "other hand, across various applications, an outstanding question involves the\n",
            "capacity of large language models to comprehend expressions of human mental\n",
            "health conditions in natural language. This study presents an initial\n",
            "evaluation of large language models in addressing this gap. Due to this, we\n",
            "compare the performance of Llama-2 and ChatGPT with classical Machine as well\n",
            "as Deep learning models. Our results on the DAIC-WOZ dataset show that\n",
            "transformer-based models, like BERT or XLNet, outperform the large language\n",
            "models.\n",
            "\n",
            "18:http://arxiv.org/abs/2401.16107v1\n",
            "Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation for Automatic Diagnosis\n",
            "Automatic diagnosis is a significant application of AI in healthcare, where\n",
            "diagnoses are generated based on the symptom description of patients. Previous\n",
            "works have approached this task directly by modeling the relationship between\n",
            "the normalized symptoms and all possible diseases. However, in the clinical\n",
            "diagnostic process, patients are initially consulted by a general practitioner\n",
            "and, if necessary, referred to specialists in specific domains for a more\n",
            "comprehensive evaluation. The final diagnosis often emerges from a\n",
            "collaborative consultation among medical specialist groups. Recently, large\n",
            "language models have shown impressive capabilities in natural language\n",
            "understanding. In this study, we adopt tuning-free LLM-based agents as medical\n",
            "practitioners and propose the Agent-derived Multi-Specialist Consultation\n",
            "(AMSC) framework to model the diagnosis process in the real world by adaptively\n",
            "fusing probability distributions of agents over potential diseases.\n",
            "Experimental results demonstrate the superiority of our approach compared with\n",
            "baselines. Notably, our approach requires significantly less parameter updating\n",
            "and training time, enhancing efficiency and practical utility. Furthermore, we\n",
            "delve into a novel perspective on the role of implicit symptoms within the\n",
            "context of automatic diagnosis.\n",
            "\n",
            "19:http://arxiv.org/abs/2402.02656v1\n",
            "RACER: An LLM-powered Methodology for Scalable Analysis of Semi-structured Mental Health Interviews\n",
            "Semi-structured interviews (SSIs) are a commonly employed data-collection\n",
            "method in healthcare research, offering in-depth qualitative insights into\n",
            "subject experiences. Despite their value, the manual analysis of SSIs is\n",
            "notoriously time-consuming and labor-intensive, in part due to the difficulty\n",
            "of extracting and categorizing emotional responses, and challenges in scaling\n",
            "human evaluation for large populations. In this study, we develop RACER, a\n",
            "Large Language Model (LLM) based expert-guided automated pipeline that\n",
            "efficiently converts raw interview transcripts into insightful domain-relevant\n",
            "themes and sub-themes. We used RACER to analyze SSIs conducted with 93\n",
            "healthcare professionals and trainees to assess the broad personal and\n",
            "professional mental health impacts of the COVID-19 crisis. RACER achieves\n",
            "moderately high agreement with two human evaluators (72%), which approaches the\n",
            "human inter-rater agreement (77%). Interestingly, LLMs and humans struggle with\n",
            "similar content involving nuanced emotional, ambivalent/dialectical, and\n",
            "psychological statements. Our study highlights the opportunities and challenges\n",
            "in using LLMs to improve research efficiency and opens new avenues for scalable\n",
            "analysis of SSIs in healthcare research.\n",
            "\n",
            "20:http://arxiv.org/abs/2402.11958v1\n",
            "Automatic Evaluation for Mental Health Counseling using LLMs\n",
            "High-quality psychological counseling is crucial for mental health worldwide,\n",
            "and timely evaluation is vital for ensuring its effectiveness. However,\n",
            "obtaining professional evaluation for each counseling session is expensive and\n",
            "challenging. Existing methods that rely on self or third-party manual reports\n",
            "to assess the quality of counseling suffer from subjective biases and\n",
            "limitations of time-consuming.\n",
            "  To address above challenges, this paper proposes an innovative and efficient\n",
            "automatic approach using large language models (LLMs) to evaluate the working\n",
            "alliance in counseling conversations. We collected a comprehensive counseling\n",
            "dataset and conducted multiple third-party evaluations based on therapeutic\n",
            "relationship theory. Our LLM-based evaluation, combined with our guidelines,\n",
            "shows high agreement with human evaluations and provides valuable insights into\n",
            "counseling scripts. This highlights the potential of LLMs as supervisory tools\n",
            "for psychotherapists. By integrating LLMs into the evaluation process, our\n",
            "approach offers a cost-effective and dependable means of assessing counseling\n",
            "quality, enhancing overall effectiveness.\n",
            "\n",
            "\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9f8b1237bad7163541.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import logging\n",
        "import gradio as gr\n",
        "from ResearchAss import llm_rephrase, get_queries, get_papers, screen_papers, generate_report, add_references, doc_to_str, ask_llm\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.DEBUG)\n",
        "\n",
        "# curate literature\n",
        "def curate_lit(user_input):\n",
        "\n",
        "    # Use LLM to produce search queries based on the user's input\n",
        "    queries = get_queries(user_input)\n",
        "    response = \"Improving your search query ... checking sources for:\\n\" + queries + \"\\n\\n\"\n",
        "\n",
        "    # Use search queries to retrieve matching papers from GoogleScholar.\n",
        "    # A combined list of all queries returned, duplicates removed.\n",
        "    papers = get_papers(queries)\n",
        "    paperstr = doc_to_str(papers)\n",
        "    prompt = \"OK here are some relevant scholarly articles I found:\"\n",
        "    llm_prompt = llm_rephrase(prompt)\n",
        "    response += llm_prompt + \"\\n\" + paperstr + \"\\n\\n\"\n",
        "    response += \"Please review the list and advise if you would like to exclude any of the papers before we proceed\"\n",
        "    return response, papers\n",
        "\n",
        "# synthesize results into a single report\n",
        "def synthesise_lit(papers, user_input):\n",
        "    report = generate_report(papers)\n",
        "    ref = add_references(papers)\n",
        "    prompt = \"Glad to have done your work for you, my lazy master. Here is your report:\"\n",
        "    llm_prompt = llm_rephrase(prompt)\n",
        "    response = llm_prompt + \"\\n\\n\" + report + \"\\n\\n\" + ref\n",
        "    prompt = \"Job done. Is there anything else I can do for you? If not, type quit\"\n",
        "    llm_prompt = llm_rephrase(prompt)\n",
        "    response += \"\\n\\n\" + llm_prompt\n",
        "    return response\n",
        "\n",
        "# Define the chatbot function\n",
        "def chatbot(user_input, history=[]):\n",
        "    try:\n",
        "        step = len(history)\n",
        "        response = \"\"\n",
        "        if step == 0:   # initial search query received\n",
        "            response = \"On it. Back in a few.\\n\\n\"\n",
        "            response, papers = curate_lit(user_input)\n",
        "            history.append(('curate_lit', papers))\n",
        "        elif step == 1: # Screen papers based on user input\n",
        "            papers = history[0][1]\n",
        "            response, scr_papers = screen_papers(papers, user_input)\n",
        "            history.append(('screen', scr_papers))\n",
        "        elif step == 2: # synthesize results into a single report\n",
        "            proceed = ask_llm(user_input)\n",
        "            if 'CONT' in proceed:\n",
        "              papers = history[1][1]\n",
        "              response = synthesise_lit(papers, user_input)\n",
        "              history.append(('synthesise', None))\n",
        "            else:\n",
        "                response = \"Don't mind my efforts, we start again. Define your search query.\\n\"\n",
        "                history = []\n",
        "        elif step == 3: # after report is generated, check if user wants a new search\n",
        "            if \"quit\" in user_input.lower():\n",
        "                response = \"Goodbye!\"\n",
        "            else:\n",
        "                response = llm_prompt\n",
        "            history = []  # Reset the history to start a new search\n",
        "\n",
        "        return response, history\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\", history\n",
        "\n",
        "# Create a Gradio interface\n",
        "prompt = \"Hi there, fellow scientist! Happy to assist. What is your research question?\"\n",
        "llm_prompt = llm_rephrase(prompt)\n",
        "\n",
        "interface = gr.Interface(\n",
        "    fn=chatbot,\n",
        "    inputs=[gr.Textbox(lines=2, placeholder=llm_prompt), gr.State([])],\n",
        "    outputs=[gr.Textbox(), gr.State()],\n",
        "    title=\"Rude Research Assistant Chatbot\",\n",
        "    description=\"This chatbot assists with research by curating literature and generating reports.\"\n",
        ")\n",
        "\n",
        "interface.launch(debug=True, share=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}